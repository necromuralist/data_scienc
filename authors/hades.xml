<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Data Science With Python (Posts by hades)</title><link>https://necromuralist.github.io/data_science/</link><description></description><atom:link rel="self" type="application/rss+xml" href="https://necromuralist.github.io/data_science/authors/hades.xml"></atom:link><language>en</language><copyright>Contents Â© 2017 &lt;a href="mailto:necromuralist@gmail.com"&gt;necromuralist&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sat, 12 Aug 2017 22:23:38 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Assignment 2 - Introduction to NLTK</title><link>https://necromuralist.github.io/data_science/posts/assignment-2-introduction-to-nltk/</link><dc:creator>hades</dc:creator><description>&lt;div&gt;&lt;p&gt;In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling.&lt;/p&gt;
&lt;div class="section" id="part-1-analyzing-moby-dick"&gt;
&lt;h2&gt;1 Part 1 - Analyzing Moby Dick&lt;/h2&gt;
&lt;div class="section" id="imports-and-data-set-up"&gt;
&lt;h3&gt;1.1 Imports and Data Set Up&lt;/h3&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.probability&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-3"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.tokenize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-4"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-5"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pyplot&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-6"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-7"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk.data&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-8"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numba&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-9"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-10"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-11"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_8cf613fd9a274ebc9446b5c05a533481-1"&gt;&lt;/a&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;a name="rest_code_8cf613fd9a274ebc9446b5c05a533481-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;If you would like to work with the raw text you can use 'moby_raw'.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_eea973cd9fb546c79bbcff91dce3dca1-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'moby.txt'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_eea973cd9fb546c79bbcff91dce3dca1-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;moby_raw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;If you would like to work with the novel in &lt;tt class="docutils literal"&gt;nltk.Text&lt;/tt&gt; format you can use 'text1'.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_bcef0d8d58ee4e0da0182473a52ac758-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bcef0d8d58ee4e0da0182473a52ac758-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bcef0d8d58ee4e0da0182473a52ac758-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="examples"&gt;
&lt;h3&gt;1.2 Examples&lt;/h3&gt;
&lt;div class="section" id="example-1"&gt;
&lt;h4&gt;1.2.1 Example 1&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;How many tokens (words and punctuation symbols) are in text1?&lt;/em&gt; A &lt;strong&gt;token&lt;/strong&gt; is a linguistic unit such as a word, punctuation mark, or alpha-numeric strings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_one&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-2"&gt;&lt;/a&gt;     &lt;span class="sd"&gt;"""counts the tokens in moby dick&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     Returns:&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;      int: number of tokens in moby dick&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     """&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-7"&gt;&lt;/a&gt;     &lt;span class="c1"&gt;# or alternatively len(text1)&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-8"&gt;&lt;/a&gt;     &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_one&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} tokens."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-12"&gt;&lt;/a&gt;     &lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 254,989 tokens.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="example-2"&gt;
&lt;h4&gt;1.2.2 Example 2&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;How many unique tokens (unique words and punctuation) does text1 have?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_two&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""counts the unique tokens&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     int: count of unique tokens in Moby Dick&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-7"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# or alternatively len(set(text1))&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_UNIQUE_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_two&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} unique tokens."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-12"&gt;&lt;/a&gt;    &lt;span class="n"&gt;MOBY_UNIQUE_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 20,755 unique tokens.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="example-3"&gt;
&lt;h4&gt;1.2.3 Example 3&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;After lemmatizing the verbs, how many unique tokens does text1 have?&lt;/em&gt; A &lt;strong&gt;lemma&lt;/strong&gt; is the canonical form. e.g. &lt;em&gt;run&lt;/em&gt; is the lemma for &lt;em&gt;runs&lt;/em&gt;, &lt;em&gt;ran&lt;/em&gt;, &lt;em&gt;running&lt;/em&gt;, and &lt;em&gt;run&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_three&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Counts the number of lemma in Moby Dick&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     int: count of unique lemma&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;lemmatizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;lemmatizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'v'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;text1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_LEMMA_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_three&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} lemma (found in WordNet)."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-12"&gt;&lt;/a&gt;    &lt;span class="n"&gt;MOBY_LEMMA_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 16,900 lemma (found in WordNet).
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="questions"&gt;
&lt;h3&gt;1.3 Questions&lt;/h3&gt;
&lt;div class="section" id="question-1"&gt;
&lt;h4&gt;1.3.1 Question 1&lt;/h4&gt;
&lt;p&gt;What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-1"&gt;&lt;/a&gt;&lt;span class="nd"&gt;@jit&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;lexical_diversity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-3"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Calculates the lexical diversity of a list of tokens&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: fraction of tokens that are unique&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_one&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Calculates the lexical diversity of Moby Dick&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: fraction of tokens that are unique&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lexical_diversity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_one&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Lexical Diversity of Moby Dick: {:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Lexical Diversity of Moby Dick: 0.08
&lt;/pre&gt;
&lt;p&gt;About 8 percent of the tokens in Moby Dick are unique.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-2"&gt;
&lt;h4&gt;1.3.2 Question 2&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What percentage of tokens is 'whale'or 'Whale'?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_a5fdbed8ce7a46fe911642650986c904-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_frequencies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_two&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""calculates percentage of tokens that are 'whale'&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: percentage of entries that are whales&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;whales&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"whale"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Whale"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;whales&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;whale_fraction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_two&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Percentage of tokens that are whales: {:.2f} %"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;whale_fraction&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Percentage of tokens that are whales: 0.41 %
&lt;/pre&gt;
&lt;p&gt;Around 1 percent of the tokens are 'whale'.&lt;/p&gt;
&lt;p&gt;I originally made two mistakes with this question, I was returning a fraction, not a percentage, and I was using a regular expression &lt;em&gt;'([Ww]hale)'&lt;/em&gt; which I later realized would match &lt;em&gt;whales&lt;/em&gt;, &lt;em&gt;whaler&lt;/em&gt;, and other variants.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
782
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-3"&gt;
&lt;h4&gt;1.3.3 Question 3&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_three&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds 20 most requently occuring tokens&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: (token, frequency) for top 20 tokens&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_three&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
[(',', 19204), ('the', 13715), ('.', 7308), ('of', 6513), ('and', 6010), ('a', 4545), ('to', 4515), (';', 4173), ('in', 3908), ('that', 2978), ('his', 2459), ('it', 2196), ('I', 2097), ('!', 1767), ('is', 1722), ('--', 1713), ('with', 1659), ('he', 1658), ('was', 1639), ('as', 1620)]
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-4"&gt;
&lt;h4&gt;1.3.4 Question 4&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What tokens have a length of greater than 5 and frequency of more than 150?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_cafd890a1d764e14954df161db5c1fff-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;a name="rest_code_cafd890a1d764e14954df161db5c1fff-2"&gt;&lt;/a&gt;                                        &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"token"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"frequency"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_four&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets tokens with length &amp;gt; 5, frequency &amp;gt; 150"""&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;frame&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-4"&gt;&lt;/a&gt;                                  &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_four&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['Captain', 'Pequod', 'Queequeg', 'Starbuck', 'almost', 'before', 'himself', 'little', 'seemed', 'should', 'though', 'through', 'whales', 'without']
&lt;/pre&gt;
&lt;p&gt;I was originally returning the data frame, not just the sorted tokens, which was of course marked wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-5"&gt;
&lt;h4&gt;1.3.5 Question 5&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Find the longest word in text1 and that word's length.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a tuple `(longest_word, length)`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_five&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds the longest word and its length&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Return:&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     tuple: (longest-word, length)&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;longest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extractall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"(?P&amp;lt;long&amp;gt;.{{{}}})"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;long&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_five&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
("twelve-o'clock-at-night", 23)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-6"&gt;
&lt;h4&gt;1.3.6 Question 6&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What unique words have a frequency of more than 2000? What is their frequency?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_2fd682584bc44b1788a3acdc9bbf5d16-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isalpha&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_six&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Finds words wih frequency &amp;gt; 2000&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: frequency, word tuples&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;common&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;2000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_six&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
[(13715, 'the'), (6513, 'of'), (6010, 'and'), (4545, 'a'), (4515, 'to'), (3908, 'in'), (2978, 'that'), (2459, 'his'), (2196, 'it'), (2097, 'I')]
&lt;/pre&gt;
&lt;p&gt;When I first submitted this I got it wrong because I was returning a list of &lt;tt class="docutils literal"&gt;(word, frequency)&lt;/tt&gt;, not &lt;tt class="docutils literal"&gt;(frequency, word)&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-7"&gt;
&lt;h4&gt;1.3.7 Question 7&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What is the average number of tokens per sentence?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_seven&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""average number of tokens per sentence"""&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_seven&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Average number of tokens per sentence: {:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Average number of tokens per sentence: 25.88
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-8"&gt;
&lt;h4&gt;1.3.8 Question 8&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What are the 5 most frequent parts of speech in this text? What is their frequency?&lt;/em&gt; Parts of Speech (POS) are the lexical categories that words belong to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_eight&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the 5 most frequent parts of speech&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list (Tuple): (part of speech, frequency) for top 5&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;tags&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;frequencies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_eight&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Top 5 parts of speech: {}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Top 5 parts of speech: [('NN', 4016), ('NNP', 2916), ('JJ', 2875), ('NNS', 2452), ('VBD', 1421)]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-2-spelling-recommender"&gt;
&lt;h2&gt;2 Part 2 - Spelling Recommender&lt;/h2&gt;
&lt;p&gt;For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.&lt;/p&gt;
&lt;p&gt;For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Each of the three different recommenders will use a different distance measure (outlined below)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.metrics.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;edit_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;jaccard_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-6"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.util&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ngrams&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_cbb722dd9c0540b1b5efa8747df55e25-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;correct_spellings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_cbb722dd9c0540b1b5efa8747df55e25-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;spellings_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;correct_spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;div class="section" id="question-9"&gt;
&lt;h3&gt;2.1 Question 9&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;`Jaccard distance &amp;lt;https://en.wikipedia.org/wiki/Jaccard_index&amp;gt;`_ on the trigrams of the two words.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three: `['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""find the closet words to each entry&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries: collection of words to match&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     gram_number: number of n-grams to use&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: words with the closest jaccard distance to entries&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-10"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-11"&gt;&lt;/a&gt;    &lt;span class="n"&gt;outcomes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;spellings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;spellings_series&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;spellings_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-14"&gt;&lt;/a&gt;        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;jaccard_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ngrams&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-15"&gt;&lt;/a&gt;                                       &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ngrams&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-16"&gt;&lt;/a&gt;                     &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-17"&gt;&lt;/a&gt;        &lt;span class="n"&gt;closest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;outcomes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;closest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-19"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;outcomes&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_nine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds the closest word based on jaccard distance"""&lt;/span&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_nine&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['corpulent', 'indecence', 'validate']
&lt;/pre&gt;
&lt;p&gt;I originally got both the Jaccard Distance problems wrong because I was just using the distance, not filtering the candidates by the first letter, which turns out to return fairly dissimilar words.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-10"&gt;
&lt;h3&gt;2.2 Question 10&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;`Jaccard distance &amp;lt;https://en.wikipedia.org/wiki/Jaccard_index&amp;gt;`_ on the 4-grams of the two words.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three: `['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_7a6050837b6343da920357d572350313-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_ten&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the neares words using jaccard-distance with 4-grams&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries (list): words to find nearest other word for&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: nearest words found&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_ten&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['cormus', 'incendiary', 'valid']
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-11"&gt;
&lt;h3&gt;2.3 Question 11&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;**`Edit (Levenshtein) distance on the two words with transpositions. &amp;lt;https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance&amp;gt;`_**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three: `['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_eleven&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the nearest words based on Levenshtein distance&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries (list[str]): words to find closest words to&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list[str]: nearest words to the entries&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;outcomes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-12"&gt;&lt;/a&gt;        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;edit_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-13"&gt;&lt;/a&gt;                                    &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-14"&gt;&lt;/a&gt;                     &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;correct_spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-15"&gt;&lt;/a&gt;        &lt;span class="n"&gt;closest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-16"&gt;&lt;/a&gt;        &lt;span class="n"&gt;outcomes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;closest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;outcomes&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-19"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_eleven&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['corpulent', 'intendence', 'validate']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="sources"&gt;
&lt;h2&gt;3 Sources&lt;/h2&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>text nltk nlp</category><guid>https://necromuralist.github.io/data_science/posts/assignment-2-introduction-to-nltk/</guid><pubDate>Sat, 12 Aug 2017 22:02:00 GMT</pubDate></item><item><title>Evaluating a Model</title><link>https://necromuralist.github.io/data_science/posts/evaluating-a-model/</link><dc:creator>hades</dc:creator><description>&lt;div&gt;&lt;p&gt;In this assignment you will train several models and evaluate how effectively they predict instances of credit-card fraud using data based on &lt;a class="reference external" href="https://www.kaggle.com/dalpozz/creditcardfraud"&gt;this dataset from Kaggle&lt;/a&gt;. This is their description:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.

Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.

The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (`http://mlg.ulb.ac.be &amp;lt;http://mlg.ulb.ac.be&amp;gt;`_) of ULB (UniversitÃ© Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on `http://mlg.ulb.ac.be/BruFence &amp;lt;http://mlg.ulb.ac.be/BruFence&amp;gt;`_ and `http://mlg.ulb.ac.be/ARTML &amp;lt;http://mlg.ulb.ac.be/ARTML&amp;gt;`_

Please cite: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015
&lt;/pre&gt;
&lt;p&gt;Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction.&lt;/p&gt;
&lt;p&gt;The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud.&lt;/p&gt;
&lt;div class="section" id="imports"&gt;
&lt;h2&gt;1 Imports&lt;/h2&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-3"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plot&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-4"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-6"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;GridSearchCV&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-9"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-10"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.svm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-11"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.dummy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DummyClassifier&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-12"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-13"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-14"&gt;&lt;/a&gt;    &lt;span class="n"&gt;auc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-15"&gt;&lt;/a&gt;    &lt;span class="n"&gt;confusion_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-16"&gt;&lt;/a&gt;    &lt;span class="n"&gt;precision_recall_curve&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-17"&gt;&lt;/a&gt;    &lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-18"&gt;&lt;/a&gt;    &lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-19"&gt;&lt;/a&gt;    &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-20"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e14aff12a40e489b8d6ca752a9703dae-21"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tabulate&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tabulate&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_64f1e3c9df0b4e10ac0ebacc67f2333f-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;DATA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"data/fraud_data.csv"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="setup-the-plotting"&gt;
&lt;h2&gt;2 Setup the plotting&lt;/h2&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_22f774a3c1ac456098de19522026415d-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;get_ipython&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'matplotlib inline'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_22f774a3c1ac456098de19522026415d-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;style&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axes_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_22f774a3c1ac456098de19522026415d-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"axes.grid"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
&lt;a name="rest_code_22f774a3c1ac456098de19522026415d-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="exploring-the-data"&gt;
&lt;h2&gt;3 Exploring the data&lt;/h2&gt;
&lt;div class="section" id="how-much-fraud-is-there"&gt;
&lt;h3&gt;3.1 How much fraud is there?&lt;/h3&gt;
&lt;p&gt;Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_9c9f4314195f48f2b40db65767986480-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DATA&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_64ebd84310d242fe96553b383fb92995-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Fraction of cases that were fraud: {0:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Class&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Class&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Fraction of cases that were fraud: 0.02
&lt;/pre&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_ee1033c2753e4d3b9bef981c1387c34a-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;countplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Class"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;img alt="fraud.png" src="https://necromuralist.github.io/data_science/posts/evaluating-a-model/fraud.png"&gt;
&lt;p&gt;So it appears that most of the cases aren't fraudulent.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="setting-up-the-training-and-testing-sets"&gt;
&lt;h2&gt;4 Setting up the training and testing sets&lt;/h2&gt;
&lt;p&gt;As always, we split the data into training and testing sets so there's no `data leakage`.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_dd893edb3b9440d795c4fc19b35657f5-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DATA&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_dd893edb3b9440d795c4fc19b35657f5-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_dd893edb3b9440d795c4fc19b35657f5-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_dd893edb3b9440d795c4fc19b35657f5-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_dd893edb3b9440d795c4fc19b35657f5-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_dd893edb3b9440d795c4fc19b35657f5-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="scores"&gt;
&lt;h2&gt;5 Scores&lt;/h2&gt;
&lt;p&gt;This is a convenience class to store the scores for the models.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ScoreKeeper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""only holds scores, doesn't create them"""&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-4"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"N/A"&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-5"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"N/A"&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-6"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"N/A"&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-7"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__sub__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-10"&gt;&lt;/a&gt;        &lt;span class="sd"&gt;"""calculates the difference between the three scores&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-12"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Args:&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-13"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         other (Scores): the right-hand side of the subtraction&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-15"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Returns:&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-16"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         ScoreKeeper: object with the differences&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-18"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Raises:&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-19"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         TypeError: one of the values wasn't set on one of the Scores&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-20"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        """&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-21"&gt;&lt;/a&gt;        &lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ScoreKeeper&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-22"&gt;&lt;/a&gt;        &lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-23"&gt;&lt;/a&gt;        &lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-24"&gt;&lt;/a&gt;        &lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-25"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;scores&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-26"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-27"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__gt__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-28"&gt;&lt;/a&gt;        &lt;span class="sd"&gt;"""compares scores&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-29"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-30"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Args:&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-31"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         other (Scores): object to compare to&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-32"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-33"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Returns:&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-34"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         bool: True if all three scores are greater than other's&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-35"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-36"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Raises:&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-37"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         TypeError: one of the values wasn't set&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-38"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        """&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-39"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-40"&gt;&lt;/a&gt;                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-41"&gt;&lt;/a&gt;                    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;other&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-42"&gt;&lt;/a&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-43"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__str__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-44"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s2"&gt;"Precision: {0:.2f}, Accuracy: {1:.2f}, Recall: {2:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-45"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-46"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_5cb872d39f8844b98ea7059ea8229d8e-47"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Scores&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ScoreKeeper&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""holds scores"""&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-4"&gt;&lt;/a&gt;        &lt;span class="sd"&gt;"""fits and scores the model&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Args:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         model: model that has been fit to the data&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         x_test: input for accuracy measurement&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         y_test: labels for scoring the model&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-10"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        """&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-11"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-12"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-13"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-14"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-15"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-16"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-17"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-18"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-19"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-20"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-21"&gt;&lt;/a&gt;    &lt;span class="nd"&gt;@property&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-22"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-23"&gt;&lt;/a&gt;        &lt;span class="sd"&gt;"""the model's predictions&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-24"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-25"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Returns:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-26"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         array: predictions for x-test&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-27"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        """&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-28"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-29"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-30"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-31"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-32"&gt;&lt;/a&gt;    &lt;span class="nd"&gt;@property&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-33"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-34"&gt;&lt;/a&gt;        &lt;span class="sd"&gt;"""the accuracy of the model's predictions&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-35"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-36"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        the fraction that was correctly predicted&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-37"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-38"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        (tp + tn)/(tp + tn + fp + fn)&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-39"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-40"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Returns:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-41"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         float: accuracy of predictions for x-test&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-42"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        """&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-43"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_accuracy&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-44"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-45"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_accuracy&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-46"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-47"&gt;&lt;/a&gt;    &lt;span class="nd"&gt;@property&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-48"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-49"&gt;&lt;/a&gt;        &lt;span class="sd"&gt;"""the recall score for the predictions&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-50"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-51"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        The fraction of true-positives penalized for missing any&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-52"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        This is the better metric when missing a case is more costly&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-53"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        than accidentally identifying a case.&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-54"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-55"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        tp / (tp + fn)&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-56"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-57"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Returns:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-58"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         float: recall of the predictions&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-59"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        """&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-60"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_recall&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-61"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-62"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_recall&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-63"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-64"&gt;&lt;/a&gt;    &lt;span class="nd"&gt;@property&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-65"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-66"&gt;&lt;/a&gt;        &lt;span class="sd"&gt;"""the precision of the test predictions&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-67"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-68"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        The fraction of true-positives penalized for false-positives&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-69"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        This is the better metric when accidentally identifying a case&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-70"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        is more costly than missing a case&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-71"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-72"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        tp / (tp + fp)&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-73"&gt;&lt;/a&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-74"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        Returns:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-75"&gt;&lt;/a&gt;&lt;span class="sd"&gt;         float: precision score&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-76"&gt;&lt;/a&gt;&lt;span class="sd"&gt;        """&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-77"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_precision&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-78"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_097ed1c90480469c9152e908adcaa0b1-79"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_precision&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="a-dummy-classifier-baseline"&gt;
&lt;h2&gt;6 A Dummy Classifier (baseline)&lt;/h2&gt;
&lt;p&gt;Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), we're going to train a &lt;a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"&gt;dummy classifier&lt;/a&gt; that classifies everything as the majority class of the training data, so we will have a baseline to compare with the other models.&lt;/p&gt;
&lt;p&gt;First we create and train it&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_601c7cf4fb7a436fa08912b8ce4a14fc-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;strategy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"most_frequent"&lt;/span&gt;
&lt;a name="rest_code_601c7cf4fb7a436fa08912b8ce4a14fc-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;dummy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DummyClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;strategy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;strategy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_601c7cf4fb7a436fa08912b8ce4a14fc-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;dummy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_601c7cf4fb7a436fa08912b8ce4a14fc-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;dummy_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Scores&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Now we make our predctions and score them&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_a79eb97adabc4cc7bd0582dabe658146-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Dummy Classifier: {0}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_scores&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Dummy Classifier: Precision: 0.00, Accuracy: 0.99, Recall: 0.00
&lt;/pre&gt;
&lt;p&gt;Since the model is always predicting that the data-points are not fraudulent (the majority case), it never returns any true positives and since both precision and recall have true positive as their numerators, they are both 0.&lt;/p&gt;
&lt;p&gt;For the accuracy we can look at the count of each class:&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_45eca46d179540ce9d80dc063083507a-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
0    5344
1      80
Name: Class, dtype: int64
&lt;/pre&gt;
&lt;p&gt;And since we know it will always predict 0, we can double-check it (the true and false positives are both 0).&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;true_positive&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;true_negative&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5344&lt;/span&gt;
&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;false_positive&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;false_negative&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;
&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;true_positive&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;true_negative&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;true_positive&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;true_negative&lt;/span&gt;
&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-6"&gt;&lt;/a&gt;                                            &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;false_positive&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;false_negative&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Accuracy: {0:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_27ce046b88f74cbdabae67d0bef914cf-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_scores&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Accuracy: 0.99
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="svc-accuracy-recall-and-precision"&gt;
&lt;h2&gt;7 SVC Accuracy, Recall and Precision&lt;/h2&gt;
&lt;p&gt;Now we're going to create a &lt;a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"&gt;Support Vector Classifier&lt;/a&gt; that uses the sklearn default valuse.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_b1380e7cf75f4dbbaa7c2f9f6f80d595-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;svc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_b1380e7cf75f4dbbaa7c2f9f6f80d595-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b1380e7cf75f4dbbaa7c2f9f6f80d595-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;svc_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Scores&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;svc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_93bd041b2d7a43db9a969368ad6f8631-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"SVC: {0}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;svc_scores&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
SVC: Precision: 1.00, Accuracy: 0.99, Recall: 0.38
&lt;/pre&gt;
&lt;p&gt;We can now compare it to the Dummy Classifier to see how it did against the baseline.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_8bfef124f6a24c55a3dd95b18b26f357-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"SVC - Dummy: {0}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;svc_scores&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;dummy_scores&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_8bfef124f6a24c55a3dd95b18b26f357-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;svc_scores&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;dummy_scores&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
SVC - Dummy: Precision: 1.00, Accuracy: 0.01, Recall: 0.38
&lt;/pre&gt;
&lt;p&gt;The SVC was much better on precision and recall (as expected) and slightly better on accuracy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="confusion-matrix"&gt;
&lt;h2&gt;8 Confusion Matrix&lt;/h2&gt;
&lt;p&gt;We're going to create a Support Vector Classifier with ``C=1e9`` and ``gamma=1e-07`` (the ``e`` is the equivalent of ``**``). Then, using the &lt;a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function"&gt;decision function&lt;/a&gt; and a threshold of -220, we're going to make our predictions and create a confusion matrix. The decision-function calculates the distance of each data point from the label, so the further a value is from 0, the further it is from the separating hyper-plane.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_7740711b47cb47bf89344c74e1d7e85b-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;error_penalty&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e9&lt;/span&gt;
&lt;a name="rest_code_7740711b47cb47bf89344c74e1d7e85b-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;kernel_coefficient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-07&lt;/span&gt;
&lt;a name="rest_code_7740711b47cb47bf89344c74e1d7e85b-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;220&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_9124d607dffe4e098a8ff7fa5d8169b9-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;svc_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;error_penalty&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gamma&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kernel_coefficient&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9124d607dffe4e098a8ff7fa5d8169b9-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;svc_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9124d607dffe4e098a8ff7fa5d8169b9-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;svc_scores_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Scores&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;svc_2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The decision_function gives us the distances which we then need to convert to labels. In this case we're going to label anything greater than -220 as a 1 and anything less as a 0.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_079213a3912f4928bb0747c7f2e9450d-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;decisions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;svc_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decision_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_079213a3912f4928bb0747c7f2e9450d-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;decisions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;decisions&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;a name="rest_code_079213a3912f4928bb0747c7f2e9450d-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;decisions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;decisions&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;a name="rest_code_079213a3912f4928bb0747c7f2e9450d-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;confusion_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;decisions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_079213a3912f4928bb0747c7f2e9450d-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Actual Positive"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Actual Negative"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Predicted Positive"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Predicted Negative"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_079213a3912f4928bb0747c7f2e9450d-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tabulate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tablefmt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"orgtbl"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_079213a3912f4928bb0747c7f2e9450d-7"&gt;&lt;/a&gt;               &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"keys"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="30%"&gt;
&lt;col width="35%"&gt;
&lt;col width="35%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;/th&gt;
&lt;th class="head"&gt;Predicted Positive&lt;/th&gt;
&lt;th class="head"&gt;Predicted Negative&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Actual Positive&lt;/td&gt;
&lt;td&gt;5320&lt;/td&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Actual Negative&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;66&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_9f5fc88335864578af65992bec06a5fe-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"SVC 2: {0}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;svc_scores_2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_9f5fc88335864578af65992bec06a5fe-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;svc_scores_2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;dummy_scores&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
SVC 2: Precision: 0.94, Accuracy: 1.00, Recall: 0.80
&lt;/pre&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_1eee4905687b461a953a4d71fb966296-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"SVC 2 - SVC Default: {0}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;svc_scores_2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;svc_scores&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
SVC 2 - SVC Default: Precision: -0.06, Accuracy: 0.01, Recall: 0.43
&lt;/pre&gt;
&lt;p&gt;This model did slightly worse with precision that the default, slightly better for accuracy but quite a bit better for recall. So if we didn't care as much about false positives it would be the better model.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="logistic-regression"&gt;
&lt;h2&gt;9 Logistic Regression&lt;/h2&gt;
&lt;p&gt;This model will be a Logistic Regression model built with the default parameters.&lt;/p&gt;
&lt;p&gt;For the logisitic regression classifier, we'll create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).&lt;/p&gt;
&lt;p&gt;Looking at the precision recall curve, what is the recall when the precision is `0.75`?
Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;y_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decision_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thresholds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;precision_recall_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_scores&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;closest_zero&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;thresholds&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;closest_zero_precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;closest_zero&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;closest_zero_recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;closest_zero&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-8"&gt;&lt;/a&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;recall_at_precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gca&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-12"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Precision-Recall Curve"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-13"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;closest_zero_precision&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;closest_zero_recall&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"o"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mew&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fillstyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'none'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-14"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Precision"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-15"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Recall"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-16"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axhline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recall_at_precision&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"r"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-17"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_72719f091b2648adb4c3991326cfcd36-18"&gt;&lt;/a&gt;&lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Precision vs Recall"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;img alt="logistic_regression_precision_recall.png" src="https://necromuralist.github.io/data_science/posts/evaluating-a-model/logistic_regression_precision_recall.png"&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_0519284ded0a45879a4778e76bfb333a-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mf"&gt;0.75&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_0519284ded0a45879a4778e76bfb333a-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;recall_at_precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_0519284ded0a45879a4778e76bfb333a-3"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Recall at precision 0.75: {0}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recall_at_precision&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Recall at precision 0.75: 0.825
&lt;/pre&gt;
&lt;p&gt;When the precision is 0.75, the recall is 0.825.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;y_score_lr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;false_positive_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;true_positive_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;roc_curve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_score_lr&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;area_under_the_curve&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;auc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;false_positive_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;true_positive_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;false_positive_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mf"&gt;0.16&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gca&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;false_positive_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;true_positive_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"ROC Curve (area={0:.2f})"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;area_under_the_curve&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-8"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axhline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;true_positive_rate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"False Positive Rate"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"True Positive Rate"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"ROC Curve"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-12"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'navy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linestyle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'--'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-13"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_9b513d0f88fb413c86d7c879f9548f83-14"&gt;&lt;/a&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_aspect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'equal'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;img alt="lr_roc.png" src="https://necromuralist.github.io/data_science/posts/evaluating-a-model/lr_roc.png"&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_46e7111d57924925b65596eaee70c182-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;false_positive_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mf"&gt;0.16&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_46e7111d57924925b65596eaee70c182-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"True positive rate where false positive rate is 0.16: {0}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;true_positive_rate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
True positive rate where false positive rate is 0.16: 0.9375
&lt;/pre&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;def true_positive_where_false(model, threshold):&lt;/dt&gt;
&lt;dd&gt;"""get the true-positive value matching the threshold for false-positive&lt;/dd&gt;
&lt;dt&gt;Args:&lt;/dt&gt;
&lt;dd&gt;model: the model fit to the data with predict_proba method&lt;/dd&gt;
&lt;dt&gt;Return:&lt;/dt&gt;
&lt;dd&gt;float: True Positive rate&lt;/dd&gt;
&lt;/dl&gt;
&lt;div class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;tt class="docutils"&gt;&amp;lt;string&amp;gt;&lt;/tt&gt;, line 466)&lt;/p&gt;
Definition list ends without a blank line; unexpected unindent.&lt;/div&gt;
&lt;p&gt;"""
y_score_lr = model.predict_proba(X_test)
false_positive_rate, true_positive_rate, _ = roc_curve(y_test, y_score_lr[:, 1])
index = numpy.where(numpy.round(false_positive_rate, 2)==0.16)[0][0]
return true_positive_rate[index]&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;def recall_where_precision(model, threshold):&lt;/dt&gt;
&lt;dd&gt;"""return recall where the first precision matches threshold&lt;/dd&gt;
&lt;dt&gt;Args:&lt;/dt&gt;
&lt;dd&gt;model: model fit to the data with decision_function
threshold (float): point to find matching recall&lt;/dd&gt;
&lt;dt&gt;Returns:&lt;/dt&gt;
&lt;dd&gt;float: recall matching precision threshold&lt;/dd&gt;
&lt;/dl&gt;
&lt;div class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;tt class="docutils"&gt;&amp;lt;string&amp;gt;&lt;/tt&gt;, line 482)&lt;/p&gt;
Definition list ends without a blank line; unexpected unindent.&lt;/div&gt;
&lt;p&gt;"""
y_scores = model.decision_function(X_test)
precision, recall, thresholds = precision_recall_curve(y_test, y_scores)
return recall[numpy.where(precision==threshold)[0][0]]&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;def answer_five():&lt;/dt&gt;
&lt;dd&gt;model = LogisticRegression()
model.fit(X_train, y_train)
recall_score = recall_where_precision(model, 0.75)
true_positive = true_positive_where_false(model, threshold=0.16)
return (recall_score, true_positive)&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;answer_five()&lt;/p&gt;
&lt;p&gt;parameters = dict(penalty=["l1", "l2"], C=[10**power for power in range(-2, 3)])
model = LogisticRegression()&lt;/p&gt;
&lt;p&gt;grid = GridSearchCV(model, parameters, scoring="recall")
grid.fit(X_train, y_train)&lt;/p&gt;
&lt;p&gt;grid.cv_results_&lt;/p&gt;
&lt;p&gt;len(grid.cv_results_["mean_test_score"])&lt;/p&gt;
&lt;p&gt;grid.cv_results_
l1 = [grid.cv_results_["mean_test_score"][index] for index in range(0, len(grid.cv_results_['mean_test_score']), 2)]
l2 = [grid.cv_results_["mean_test_score"][index] for index in range(1, len(grid.cv_results_["mean_test_score"])+ 1, 2)]
l1&lt;/p&gt;
&lt;p&gt;l2&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;def answer_six():&lt;/dt&gt;
&lt;dd&gt;parameters = dict(penalty=["l1", "l2"], C=[10**power for power in range(-2, 3)])
model = LogisticRegression()
grid = GridSearchCV(model, parameters, scoring="recall")
grid.fit(X_train, y_train)
l1 = [grid.cv_results_["mean_test_score"][index] for index in range(0, len(grid.cv_results_['mean_test_score']), 2)]
l2 = [grid.cv_results_["mean_test_score"][index] for index in range(1, len(grid.cv_results_["mean_test_score"])+ 1, 2)]
return numpy.array([l1, l2]).T&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;answer_six()&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;def GridSearch_Heatmap(scores):&lt;/dt&gt;
&lt;dd&gt;get_ipython().magic('matplotlib inline')
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure()
scores = answer_six()
sns.heatmap(scores, xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])
plt.yticks(rotation=0);&lt;/dd&gt;
&lt;dt&gt;if VERBOSE:&lt;/dt&gt;
&lt;dd&gt;GridSearch_Heatmap(answer_six())&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>machinelearning kaggle</category><guid>https://necromuralist.github.io/data_science/posts/evaluating-a-model/</guid><pubDate>Mon, 12 Jun 2017 22:05:00 GMT</pubDate></item></channel></rss>