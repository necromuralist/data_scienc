* Imports and Setup
#+BEGIN_SRC ipython :session nationaldata :results none
# python standard library
import os

# third-party
import matplotlib.pyplot as pyplot
import numpy
import pandas
import seaborn
#+END_SRC

#+BEGIN_SRC ipython :session nationaldata :results none
% matplotlib inline
style = seaborn.axes_style("whitegrid")
style["axes.grid"] = False
seaborn.set_style("whitegrid", style)
#+END_SRC

  #+BEGIN_SRC ipython :session nationaldata :results none
  EMPLOYMENT_DATA = "portland_hillsboro_vancouver_2007_2017.csv"
  EMPLOYMENT_URL = ("https://www.dropbox.com/s/gafy5iddilo26wk/"
                    "portland_hillsboro_vancouver_"
                    "employment_2007_2017.csv?dl=1")
  #+END_SRC
* Data
** Downloading
  The data represents  `Local Area Unemployment Statistics` for the *Portland-Hillsboro-Vancouver* area in Oregon and was taken from the [[https://data.bls.gov/cgi-bin/surveymost?la+41][Bureau of Labor Statistics]].  It has monthly values starting from January 2007 and contiues through February 2017.

  I couldn't find a way to make a permanent link to it so I saved it to [[https://www.dropbox.com/s/gafy5iddilo26wk/portland_hillsboro_vancouver_employment_2007_2017.csv?dl=1][dropbox]]. This is some information taken from the page.

  | Item                    | Value                                                                               |
  |-------------------------+-------------------------------------------------------------------------------------|
  | Data extracted on       | April 25, 2017 (3:13:28 PM)                                                         |
  | Series Id               | LAUMT413890000000003,LAUMT413890000000004,LAUMT413890000000005,LAUMT413890000000006 |
  | Not Seasonally Adjusted |                                                                                     |
  | Area                    | Portland-Vancouver-Hillsboro, OR-WA Metropolitan Statistical Area                   |
  | Area Type               | Metropolitan areas                                                                  |
  | State/Region/Division   | Oregon                                                                              |

  #+BEGIN_SRC ipython :session nationaldata :results none
  if not os.path.isfile(EMPLOYMENT_DATA):
      response = requests.get(EMPLOYMENT_URL)
      with open(EMPLOYMENT_DATA, 'w') as writer:
          writer.write(response.text)
  data = pandas.read_csv(EMPLOYMENT_DATA)
  #+END_SRC

  #+BEGIN_SRC ipython :session nationaldata
  data.describe()
  #+END_SRC

  #+RESULTS:
  :               Year
  : count   122.000000
  : mean   2011.590164
  : std       2.945101
  : min    2007.000000
  : 25%    2009.000000
  : 50%    2012.000000
  : 75%    2014.000000
  : max    2017.000000

  #+BEGIN_SRC ipython :session nationaldata
  data.head()
  #+END_SRC

  #+RESULTS:
  :    Year Period labor force employment unemployment unemployment rate
  : 0  2007    Jan     1134639    1073299        61340               5.4
  : 1  2007    Feb     1138297    1075914        62383               5.5
  : 2  2007    Mar     1139649    1079579        60070               5.3
  : 3  2007    Apr     1135817    1079570        56247               5.0
  : 4  2007    May     1135088    1081737        53351               4.7

  For some reason there are more columns in the data then there are in the =describe= method.

  #+BEGIN_SRC ipython :session nationaldata
  data.tail()
  #+END_SRC

  #+RESULTS:
  :      Year Period labor force  employment unemployment unemployment rate
  : 117  2016    Oct  1287314(R)  1229779(R)     57535(R)            4.5(R)
  : 118  2016    Nov  1289464(R)  1235529(R)     53935(R)            4.2(R)
  : 119  2016    Dec  1282972(R)  1231411(R)     51561(R)            4.0(R)
  : 120  2017    Jan     1278225     1223966        54259               4.2
  : 121  2017    Feb  1284347(P)  1234703(P)     49644(P)            3.9(P)

  It turns out that the Bureau adds extra labels to the data. According to the site there are two.

  | Label | Meaning                                          |
  |-------+--------------------------------------------------|
  | R     | Data were subject to revision on April 21, 2017. |
  | P     | Preliminary.                                     |

** Cleaning
   I'm going to remove the labels but first I'll re-name the columns with spaces in their names to make it closer to my naming convention.

   #+BEGIN_SRC ipython :session nationaldata
   data.rename(columns={"labor force": "labor_force",
                        "unemployment rate": "unemployment_rate"},
               inplace=True)
   data.columns
   #+END_SRC

   #+RESULTS:
   : Index(['Year', 'Period', 'labor_force', 'employment', 'unemployment',
   :        'unemployment_rate'],
   :       dtype='object')
   
   Now I'll strip the labels.

   #+BEGIN_SRC ipython :session nationaldata
   pattern = "\(R\)||\(P\)"
   columns = ["labor_force", "employment", "unemployment", "unemployment_rate"]
   for column in columns:
       data[column] = data[column].str.rstrip(pattern)
   data.describe()
   #+END_SRC

   #+RESULTS:
   :               Year
   : count   122.000000
   : mean   2011.590164
   : std       2.945101
   : min    2007.000000
   : 25%    2009.000000
   : 50%    2012.000000
   : 75%    2014.000000
   : max    2017.000000

   The data still isn't picking up the other columns, possibly because I didn't re-cast them to numbers.

#+BEGIN_SRC ipython :session nationaldata
data.tail()
#+END_SRC

#+RESULTS:
:      Year Period labor_force employment unemployment unemployment_rate
: 117  2016    Oct     1287314    1229779        57535               4.5
: 118  2016    Nov     1289464    1235529        53935               4.2
: 119  2016    Dec     1282972    1231411        51561               4.0
: 120  2017    Jan     1278225    1223966        54259               4.2
: 121  2017    Feb     1284347    1234703        49644               3.9

#+BEGIN_SRC ipython :session nationaldata
data[columns] = data[columns].apply(pandas.to_numeric)
data.describe()
#+END_SRC

#+RESULTS:
#+begin_example
              Year   labor_force    employment   unemployment  \
count   122.000000  1.220000e+02  1.220000e+02     122.000000   
mean   2011.590164  1.201675e+06  1.115516e+06   86158.557377   
std       2.945101  3.660963e+04  4.724591e+04   26167.286950   
min    2007.000000  1.134639e+06  1.047621e+06   49644.000000   
25%    2009.000000  1.180418e+06  1.088475e+06   63107.500000   
50%    2012.000000  1.200312e+06  1.102644e+06   79834.500000   
75%    2014.000000  1.214507e+06  1.133689e+06  107976.250000   
max    2017.000000  1.289464e+06  1.235529e+06  136640.000000   

       unemployment_rate  
count         122.000000  
mean            7.181967  
std             2.203154  
min             3.900000  
25%             5.300000  
50%             6.750000  
75%             8.875000  
max            11.400000  
#+end_example

** Creating Date-Times

   To make a time-series we need to create an extra column from the *Year* and *Period* (month) columns.

   #+BEGIN_SRC ipython :session nationaldata
   data["date"] = data.apply(lambda x: "{0}-{1}".format(x.Period, x.Year), axis=1)
   data.head()
   #+END_SRC

   #+RESULTS:
   #+begin_example
      Year Period  labor_force  employment  unemployment  unemployment_rate  \
   0  2007    Jan      1134639     1073299         61340                5.4   
   1  2007    Feb      1138297     1075914         62383                5.5   
   2  2007    Mar      1139649     1079579         60070                5.3   
   3  2007    Apr      1135817     1079570         56247                5.0   
   4  2007    May      1135088     1081737         53351                4.7   

          date  
   0  Jan-2007  
   1  Feb-2007  
   2  Mar-2007  
   3  Apr-2007  
   4  May-2007  
#+end_example
   
* Unemployment Rate Over Time

  #+BEGIN_SRC ipython :session nationaldata :file /tmp/unemployment_over_time.png
  figure = pyplot.figure(figsize=(10, 10))
  axe = figure.gca()
  data.plot(x="date", y="unemployment_rate", ax=axe, label="Unemployment Rate")
  axe.set_title("Portland-Hillsboro-Vancouver Unemployment Over Time")
  axe.set_ylabel("% Unemployed")
  axe.set_xlabel("Month")
  seaborn.despine()
  #+END_SRC

  #+RESULTS:
  [[file:/tmp/unemployment_over_time.png]]
** One Year
   #+BEGIN_SRC ipython :session nationaldata :results none
   year = data[data.Year > 2015]
   year = year[year.date != "Jan-2016"]
   #+END_SRC

   #+BEGIN_SRC ipython :session nationaldata :file /tmp/unemployment_year.png
   figure = pyplot.figure(figsize=(10, 10))
   axe = figure.gca()
   year.plot(x='date', y="unemployment_rate", ax=axe)
   seaborn.despine()
   #+END_SRC

   #+RESULTS:
   [[file:/tmp/unemployment_year.png]]
** By year
   #+BEGIN_SRC ipython :session nationaldata :file /tmp/unemployment_years.png
   figure = pyplot.figure(figsize=(10,10))
   axe = figure.gca()
   years = data[data.Year < 2017]
   for year in years.Year.unique():
       data[data.Year == year].plot(x="Period", y="unemployment_rate", ax=axe, label=str(year))
   seaborn.despine()
   source = data[data.Year == 2016]
   axe.set_ylabel("% Unemployment")
   axe.set_xlabel("Month")
   axe.set_title("Portland-Hillsboro-Vancouver Unemployment Rate by Month")
   #+END_SRC

   #+RESULTS:
   [[file:/tmp/unemployment_years.png]]

   

* National
#+BEGIN_SRC sh
ls
#+END_SRC

#+RESULTS:
| Assignment4.ipynb                          |
| assignment_4.org                           |
| assignment4_rubric.pdf                     |
| descriptions.org                           |
| national_2007_2017.csv                     |
| national_data.org                          |
| national_unemployment_2007_2017.csv        |
| portland_hillsboro_vancouver_2007_2017.csv |
| re_check.csv                               |
| SP500.csv                                  |
| SP500_index.csv                            |
| SP500_ln.csv                               |
| Week4.ipynb                                |

#+BEGIN_SRC ipython :session nationaldata
NATIONAL_PATH = "national_unemployment_2007_2017.csv"
national_data = pandas.read_csv(NATIONAL_PATH, na_values=" ")
national_data.describe()
#+END_SRC

#+RESULTS:
#+begin_example
              Year        Jan        Feb        Mar        Apr       May  \
count    11.000000  11.000000  11.000000  11.000000  10.000000  10.00000   
mean   2012.000000   6.781818   6.754545   6.763636   6.990000   7.00000   
std       3.316625   1.895161   1.942866   1.991117   2.001916   1.98774   
min    2007.000000   4.600000   4.500000   4.400000   4.500000   4.40000   
25%    2009.500000   4.950000   4.900000   5.050000   5.100000   5.42500   
50%    2012.000000   6.600000   6.700000   6.700000   6.900000   6.90000   
75%    2014.500000   8.150000   8.300000   8.450000   8.800000   8.80000   
max    2017.000000   9.800000   9.800000   9.900000   9.900000   9.60000   

            Jun        Jul        Aug        Sep        Oct        Nov  \
count  10.00000  10.000000  10.000000  10.000000  10.000000  10.000000   
mean    7.02000   7.020000   7.040000   6.990000   6.990000   6.980000   
std     1.94182   1.901929   1.929997   1.957578   1.964943   1.995439   
min     4.60000   4.700000   4.600000   4.700000   4.700000   4.600000   
25%     5.37500   5.350000   5.350000   5.225000   5.175000   5.200000   
50%     6.80000   6.750000   6.750000   6.650000   6.850000   6.850000   
75%     8.87500   8.800000   8.775000   8.700000   8.550000   8.375000   
max     9.50000   9.500000   9.600000   9.800000  10.000000   9.900000   

             Dec  
count  10.000000  
mean    6.990000  
std     1.891178  
min     4.700000  
25%     5.150000  
50%     7.000000  
75%     8.350000  
max     9.900000  
#+end_example

#+BEGIN_SRC ipython :session nationaldata
national_data
#+END_SRC

#+RESULTS:
#+begin_example
    Year  Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep   Oct  Nov  Dec
0   2007  4.6  4.5  4.4  4.5  4.4  4.6  4.7  4.6  4.7   4.7  4.7  5.0
1   2008  5.0  4.9  5.1  5.0  5.4  5.6  5.8  6.1  6.1   6.5  6.8  7.3
2   2009  7.8  8.3  8.7  9.0  9.4  9.5  9.5  9.6  9.8  10.0  9.9  9.9
3   2010  9.8  9.8  9.9  9.9  9.6  9.4  9.4  9.5  9.5   9.4  9.8  9.3
4   2011  9.1  9.0  9.0  9.1  9.0  9.1  9.0  9.0  9.0   8.8  8.6  8.5
5   2012  8.3  8.3  8.2  8.2  8.2  8.2  8.2  8.1  7.8   7.8  7.7  7.9
6   2013  8.0  7.7  7.5  7.6  7.5  7.5  7.3  7.3  7.2   7.2  6.9  6.7
7   2014  6.6  6.7  6.7  6.2  6.3  6.1  6.2  6.2  5.9   5.7  5.8  5.6
8   2015  5.7  5.5  5.4  5.4  5.5  5.3  5.2  5.1  5.0   5.0  5.0  5.0
9   2016  4.9  4.9  5.0  5.0  4.7  4.9  4.9  4.9  4.9   4.8  4.6  4.7
10  2017  4.8  4.7  4.5  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  NaN
#+end_example

The national data has one more month than the regional data so I'll remove it.
#+BEGIN_SRC ipython :session nationaldata
national_data.set_value(10, "Mar", numpy.nan)
national_data
#+END_SRC

#+RESULTS:
#+begin_example
    Year  Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep   Oct  Nov  Dec
0   2007  4.6  4.5  4.4  4.5  4.4  4.6  4.7  4.6  4.7   4.7  4.7  5.0
1   2008  5.0  4.9  5.1  5.0  5.4  5.6  5.8  6.1  6.1   6.5  6.8  7.3
2   2009  7.8  8.3  8.7  9.0  9.4  9.5  9.5  9.6  9.8  10.0  9.9  9.9
3   2010  9.8  9.8  9.9  9.9  9.6  9.4  9.4  9.5  9.5   9.4  9.8  9.3
4   2011  9.1  9.0  9.0  9.1  9.0  9.1  9.0  9.0  9.0   8.8  8.6  8.5
5   2012  8.3  8.3  8.2  8.2  8.2  8.2  8.2  8.1  7.8   7.8  7.7  7.9
6   2013  8.0  7.7  7.5  7.6  7.5  7.5  7.3  7.3  7.2   7.2  6.9  6.7
7   2014  6.6  6.7  6.7  6.2  6.3  6.1  6.2  6.2  5.9   5.7  5.8  5.6
8   2015  5.7  5.5  5.4  5.4  5.5  5.3  5.2  5.1  5.0   5.0  5.0  5.0
9   2016  4.9  4.9  5.0  5.0  4.7  4.9  4.9  4.9  4.9   4.8  4.6  4.7
10  2017  4.8  4.7  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  NaN
#+end_example

#+BEGIN_SRC ipython :session nationaldata
transposed = national_data.T
transposed
#+END_SRC

#+RESULTS:
#+begin_example
          0       1       2       3       4       5       6       7       8   \
Year  2007.0  2008.0  2009.0  2010.0  2011.0  2012.0  2013.0  2014.0  2015.0   
Jan      4.6     5.0     7.8     9.8     9.1     8.3     8.0     6.6     5.7   
Feb      4.5     4.9     8.3     9.8     9.0     8.3     7.7     6.7     5.5   
Mar      4.4     5.1     8.7     9.9     9.0     8.2     7.5     6.7     5.4   
Apr      4.5     5.0     9.0     9.9     9.1     8.2     7.6     6.2     5.4   
May      4.4     5.4     9.4     9.6     9.0     8.2     7.5     6.3     5.5   
Jun      4.6     5.6     9.5     9.4     9.1     8.2     7.5     6.1     5.3   
Jul      4.7     5.8     9.5     9.4     9.0     8.2     7.3     6.2     5.2   
Aug      4.6     6.1     9.6     9.5     9.0     8.1     7.3     6.2     5.1   
Sep      4.7     6.1     9.8     9.5     9.0     7.8     7.2     5.9     5.0   
Oct      4.7     6.5    10.0     9.4     8.8     7.8     7.2     5.7     5.0   
Nov      4.7     6.8     9.9     9.8     8.6     7.7     6.9     5.8     5.0   
Dec      5.0     7.3     9.9     9.3     8.5     7.9     6.7     5.6     5.0   

          9       10  
Year  2016.0  2017.0  
Jan      4.9     4.8  
Feb      4.9     4.7  
Mar      5.0     NaN  
Apr      5.0     NaN  
May      4.7     NaN  
Jun      4.9     NaN  
Jul      4.9     NaN  
Aug      4.9     NaN  
Sep      4.9     NaN  
Oct      4.8     NaN  
Nov      4.6     NaN  
Dec      4.7     NaN  
#+end_example

#+BEGIN_SRC ipython :session nationaldata
years = transposed.ix["Year"]
years = years.apply(lambda x: int(x))
years
#+END_SRC

#+RESULTS:
#+begin_example
0     2007
1     2008
2     2009
3     2010
4     2011
5     2012
6     2013
7     2014
8     2015
9     2016
10    2017
Name: Year, dtype: int64
#+end_example

#+BEGIN_SRC ipython :session nationaldata
transposed.drop("Year", inplace=True)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session nationaldata
transposed.columns = years
transposed
#+END_SRC

#+RESULTS:
#+begin_example
Year  2007  2008  2009  2010  2011  2012  2013  2014  2015  2016  2017
Jan    4.6   5.0   7.8   9.8   9.1   8.3   8.0   6.6   5.7   4.9   4.8
Feb    4.5   4.9   8.3   9.8   9.0   8.3   7.7   6.7   5.5   4.9   4.7
Mar    4.4   5.1   8.7   9.9   9.0   8.2   7.5   6.7   5.4   5.0   NaN
Apr    4.5   5.0   9.0   9.9   9.1   8.2   7.6   6.2   5.4   5.0   NaN
May    4.4   5.4   9.4   9.6   9.0   8.2   7.5   6.3   5.5   4.7   NaN
Jun    4.6   5.6   9.5   9.4   9.1   8.2   7.5   6.1   5.3   4.9   NaN
Jul    4.7   5.8   9.5   9.4   9.0   8.2   7.3   6.2   5.2   4.9   NaN
Aug    4.6   6.1   9.6   9.5   9.0   8.1   7.3   6.2   5.1   4.9   NaN
Sep    4.7   6.1   9.8   9.5   9.0   7.8   7.2   5.9   5.0   4.9   NaN
Oct    4.7   6.5  10.0   9.4   8.8   7.8   7.2   5.7   5.0   4.8   NaN
Nov    4.7   6.8   9.9   9.8   8.6   7.7   6.9   5.8   5.0   4.6   NaN
Dec    5.0   7.3   9.9   9.3   8.5   7.9   6.7   5.6   5.0   4.7   NaN
#+end_example

#+BEGIN_SRC ipython :session nationaldata
stacked = transposed.stack().reset_index()
stacked.head()
#+END_SRC

#+RESULTS:
:   level_0  Year    0
: 0     Jan  2007  4.6
: 1     Jan  2008  5.0
: 2     Jan  2009  7.8
: 3     Jan  2010  9.8
: 4     Jan  2011  9.1

#+BEGIN_SRC ipython :session nationaldata
stacked.columns = ["Month", "Year", "Unemployment Data"]
stacked.head()
#+END_SRC

#+RESULTS:
:   Month  Year  Unemployment Data
: 0   Jan  2007                4.6
: 1   Jan  2008                5.0
: 2   Jan  2009                7.8
: 3   Jan  2010                9.8
: 4   Jan  2011                9.1

#+BEGIN_SRC ipython :session nationaldata
stacked["Period"] = stacked.apply(lambda x: "{0}-{1}".format(x.Month, x.Year), axis=1)
month_map = dict(zip(national_data.columns[1:], range(12)))
stacked["month_index"] = stacked.Month.apply(lambda x: month_map[x])
stacked.head()
#+END_SRC

#+RESULTS:
:   Month  Year  Unemployment Data    Period  month_index
: 0   Jan  2007                4.6  Jan-2007            0
: 1   Jan  2008                5.0  Jan-2008            0
: 2   Jan  2009                7.8  Jan-2009            0
: 3   Jan  2010                9.8  Jan-2010            0
: 4   Jan  2011                9.1  Jan-2011            0

#+BEGIN_SRC ipython :session nationaldata
sorted_data = stacked.sort_values(["Year", "month_index"])
sorted_data.head()
#+END_SRC

#+RESULTS:
:    Month  Year  Unemployment Data    Period  month_index
: 0    Jan  2007                4.6  Jan-2007            0
: 11   Feb  2007                4.5  Feb-2007            1
: 22   Mar  2007                4.4  Mar-2007            2
: 32   Apr  2007                4.5  Apr-2007            3
: 42   May  2007                4.4  May-2007            4

#+BEGIN_SRC ipython :session nationaldata
last = sorted_data.Month.count()
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session nationaldata :file /tmp/national_unemployment.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
sorted_data.plot(x="Month", y="Unemployment Data", ax=axe, label="National")
data.plot(x="date", y="unemployment_rate", ax=axe, label="Portland-Hllsboro-Vancouver")
axe.set_ylabel("% Unemployment")
axe.set_title("National Unemployment Rate Over Time")
axe.text(last, sorted_data["Unemployment Data"].iloc[-1], "National")
axe.text(last, data["unemployment_rate"].iloc[-1], "Portland-Hillsboro-Vancouver")
maximum_y = data.unemployment_rate.max()
axe.set_ylim(0, maximum_y)
seaborn.despine()
#+END_SRC

#+RESULTS:
[[file:/tmp/national_unemployment.png]]
* S&P 500

The S&P 500 data came from the [[https://fred.stlouisfed.org/series/SP500/downloaddata][Federal Reserve Bank of St. Louis]]. It contains the S&P 500 monthly index from May 2007 through February 2017.

#+BEGIN_SRC ipython :session nationaldata
s_and_p = pandas.read_csv("SP500.csv", na_values='.')
s_and_p.describe()
#+END_SRC  

#+RESULTS:
:             VALUE
: count  117.000000
: mean     0.452099
: std      3.968743
: min    -20.395070
: 25%     -0.964300
: 50%      1.188780
: 75%      2.840150
: max     12.021710

#+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/s_and_p.png
s_and_p.plot(x="DATE", y="VALUE")
#+END_SRC

#+RESULTS:
[[file:/tmp/course_4/s_and_p.png]]

#+BEGIN_SRC ipython :session nationaldata
s_and_p_ln = pandas.read_csv("SP500_ln.csv", na_values='.')
s_and_p_ln.describe()
#+END_SRC

#+RESULTS:
:             VALUE
: count  118.000000
: mean     7.297456
: std      0.276280
: min      6.629530
: 25%      7.106075
: 50%      7.272825
: 75%      7.571793
: max      7.753580


#+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/s_and_p_ln.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
sorted_data.plot(x="Month", y="Unemployment Data", ax=axe, legend=False)
data.plot(x="date", y="unemployment_rate", ax=axe, legend=False)
s_and_p_ln.plot(x="DATE", y="VALUE", ax = axe, legend=False)
axe.set_ylabel("% Unemployment")
axe.set_title("Unemployment Rate April 2007 To February 2017 with ln(S&P 500)")
axe.text(last, sorted_data["Unemployment Data"].iloc[-1], "National")
axe.text(last, data["unemployment_rate"].iloc[-1], "Portland-Hillsboro-Vancouver")
axe.text(last, s_and_p_ln["VALUE"].iloc[-1], "ln(S&P 500 Index)")
seaborn.despine()
#+END_SRC

#+RESULTS:
[[file:/tmp/course_4/s_and_p_ln.png]]

#+BEGIN_SRC ipython :session nationaldata
s_and_p_index = pandas.read_csv("SP500_index.csv", na_values=".")
s_and_p_index.describe()
#+END_SRC

#+RESULTS:
:              VALUE
: count   118.000000
: mean   1531.959237
: std     409.400311
: min     757.130000
: 25%    1219.360000
: 50%    1440.620000
: 75%    1942.617500
: max    2329.910000

#+BEGIN_SRC ipython :session nationaldata :results output
print(len(sorted_data))
print(len(data))
print(len(s_and_p_index))
#+END_SRC

#+RESULTS:
: 122
: 122
: 119

#+BEGIN_SRC ipython :session nationaldata
sorted_data.head()
#+END_SRC

#+RESULTS:
:    Month  Year  Unemployment Data    Period  month_index
: 0    Jan  2007                4.6  Jan-2007            0
: 11   Feb  2007                4.5  Feb-2007            1
: 22   Mar  2007                4.4  Mar-2007            2
: 32   Apr  2007                4.5  Apr-2007            3
: 42   May  2007                4.4  May-2007            4

#+BEGIN_SRC ipython :session nationaldata :file /tmp/course_4/s_and_p_index.png
figure = pyplot.figure(figsize=(10, 10))
axe = figure.gca()
axe.plot(s_and_p_index.VALUE, data.unemployment_rate[3:])
axe.plot(s_and_p_index.VALUE, sorted_data["Unemployment Data"][3:])
axe.set_title("Unemployment Rate vs S&P 500")
axe.set_xlabel("S&P 500 Index")
axe.set_ylabel("% Unemployment")
last = s_and_p_index.VALUE.iloc[-1] + 100
axe.text(last, sorted_data["Unemployment Data"].iloc[-1], "National")
axe.text(last, data["unemployment_rate"].iloc[-1], "Portland-Hillsboro-Vancouver")
seaborn.despine()
# sorted_data.plot(x="Month", y="Unemployment Data", ax=axe, label="National")
# data.plot(x="date", y="unemployment_rate", ax=axe, label="Portland-Hllsboro-Vancouver")
# axe.set_ylabel("% Unemployment")
# axe.set_title("National Unemployment Rate Over Time")
# axe.text(last, sorted_data["Unemployment Data"].iloc[-1], "National")
# axe.text(last, data["unemployment_rate"].iloc[-1], "Portland-Hillsboro-Vancouver")
# #maximum_y = s_and_p_index.VALUE.max()
# #axe.set_ylim(0, maximum_y)
# seaborn.despine()
# s_and_p_index.plot(x="DATE", y="VALUE", ax=axe)
#+END_SRC

#+RESULTS:
[[file:/tmp/course_4/s_and_p_index.png]]
