#+TITLE: Predicting Future Connections

This will select a model to predict whether an edge in the email-network that currently doesn't have an edge will have one in the future.

* Imports

#+BEGIN_SRC ipython :session futures :results none 
# pypi
import networkx
import pandas
import seaborn

from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
    )
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV,
    StratifiedKFold,
    )
from sklearn.preprocessing import StandardScaler
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none 
% matplotlib inline
seaborn.set_style("whitegrid")
#+END_SRC

* Constants

#+BEGIN_SRC ipython :session futures :results none
class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
#+END_SRC

* The Email-Graph
  To get the features for the models we'll need to use the email-graph.

#+BEGIN_SRC ipython :session futures :results none
email = networkx.read_gpickle(Futures.graph_file)
#+END_SRC

* The Data

** The Given Data 
   We're given a csv file with the training and prediction data in it ('Future_Connections.csv').
#+BEGIN_SRC sh
head Future_Connections.csv
echo
#+END_SRC

#+RESULTS:
|            | Future Connection |
| (6, 840)   |               0.0 |
| (4, 197)   |               0.0 |
| (620, 979) |               0.0 |
| (519, 872) |               0.0 |
| (382, 423) |               0.0 |
| (97, 226)  |               1.0 |
| (349, 905) |               0.0 |
| (429, 860) |               0.0 |
| (309, 989) |               0.0 |

Org-mode converted it to a table, but it's actually a CSV. The first line of data looks like this.

#+BEGIN_EXAMPLE
"(6, 840)",0.0
#+END_EXAMPLE


#+BEGIN_SRC ipython :session futures :results none
future_connections = pandas.read_csv(Futures.data_file,
                                     index_col=0,
                                     converters={0: eval})
#+END_SRC

So, we're loading the node-pairs (edges) as the index of the data-frame and explicitly telling pandas that the Future Connection values should be converted , which I don't think is necessary, but this came with the problem statement so I'll just leave it in in case there's some side-effect I'm not aware of.

#+BEGIN_SRC ipython :session futures :results output
print(future_connections[Futures.target].value_counts())
#+END_SRC

#+RESULTS:
: 0.0    337002
: 1.0     29332
: Name: Future Connection, dtype: int64

This is a fairly big (and lopsided) data-set.

#+BEGIN_SRC ipython :session futures :file /tmp/future_connections_counts.png
seaborn.countplot(x=Futures.target, data=future_connections)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_connections_counts.png]]

* Adding networkx features
   To create features to train the model and make predictions, I'm going to use the networkx [[https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.link_prediction.html][link prediction]] algorithms.

** Add Networkx Data
   This is a function to get networkx data and add it to the data-frame. It won't work for the community-based algorithms.

#+BEGIN_SRC ipython :session futures :results none
def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
                   for output in adder(graph, frame.index)]
    return frame
#+END_SRC

** Adding A Resource Allocation Index

#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.resource_allocation_index,
                  DataNames.resource_allocation)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation
: (6, 840)                0.0             0.136721

** Adding the Jaccard Coefficient
#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient
: (6, 840)                0.0             0.136721              0.07377

** Adamic Adar

#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  
: (6, 840)     2.110314  

** Preferential Attachment
#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  preferential_attachment  
: (6, 840)     2.110314                     2070  

** Community-Based Link Prediction
   This requires identifying 'communities' first, so I'll defer it for now.
#+BEGIN_SRC ipython :session futures :results none
#add_networkx_data(networkx.cn_soundarajan_hopcroft, DataNames.common_neighbors)
#+END_SRC

These three all require communities for them to work (so I'm skipping them):
   - cn_soundarajan_hopcroft
   - ra_index_soundarajan_hopcroft
   - within_inter_cluster

* Setup the Training and Testing Data
** Separating the Edges Without 'Future Connection' Values
   We are going to train on the values in the data with predictions and then make predictions for those that don't. For model selection we don't need the set missing predictions, but I'll separate it out anyway to be complete.

#+BEGIN_SRC ipython :session futures :results none
prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
#+END_SRC

#+RESULTS:
: (122112, 5)
: (366334, 5)

** Separate the Target and Training Sets
#+BEGIN_SRC ipython :session futures :results none
non_target = [column for column in future_connections.columns
              if column != Futures.target]
training = training_set[non_target]
testing = training_set[Futures.target]
predictions = prediction_set[non_target]
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
assert all(training.columns == predictions.columns)
assert len(training) == len(testing)
#+END_SRC

** Setting Up the Testing and Training Sets
#+BEGIN_SRC ipython :session futures :results none
x_train, x_test, y_train, y_test = train_test_split(training, testing, stratify=testing)
#+END_SRC

#+BEGIN_SRC ipython :session futures :file /tmp/future_training.png
seaborn.countplot(y_train)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_training.png]]

#+BEGIN_SRC ipython :session futures :file /tmp/future_testing.png
seaborn.countplot(y_test)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_testing.png]]

** Scaling the Data
   To enable the use of linear models I'm going to scale the data so the mean is 0 and the variace is 1.

#+BEGIN_SRC ipython :session futures :results none
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

x_train = pandas.DataFrame(x_train, columns=training.columns)
x_test = pandas.DataFrame(x_test, columns=training.columns)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(x_train.describe())
print(x_test.describe())
#+END_SRC

#+RESULTS:
#+begin_example
       resource_allocation  jaccard_coefficient   adamic_adar  \
count         2.747500e+05         2.747500e+05  2.747500e+05   
mean          3.015443e-17         5.410211e-17  1.030319e-16   
std           1.000002e+00         1.000002e+00  1.000002e+00   
min          -3.767579e-01        -5.328067e-01 -4.286897e-01   
25%          -3.767579e-01        -5.328067e-01 -4.286897e-01   
50%          -3.767579e-01        -5.328067e-01 -4.286897e-01   
75%          -7.664838e-02         1.910276e-01  4.807542e-03   
max           6.178179e+01         2.624906e+01  4.446243e+01   

       preferential_attachment  
count             2.747500e+05  
mean             -2.772345e-17  
std               1.000002e+00  
min              -5.412848e-01  
25%              -5.018600e-01  
50%              -3.698727e-01  
75%               7.522729e-02  
max               4.268027e+01  
       resource_allocation  jaccard_coefficient   adamic_adar  \
count         91584.000000         91584.000000  91584.000000   
mean             -0.000557             0.000105      0.001936   
std               0.977113             0.993116      0.979893   
min              -0.376758            -0.532807     -0.428690   
25%              -0.376758            -0.532807     -0.428690   
50%              -0.376758            -0.532807     -0.428690   
75%              -0.074839             0.191028      0.007461   
max              40.227245            26.249063     26.162102   

       preferential_attachment  
count             91584.000000  
mean                  0.004802  
std                   0.986914  
min                  -0.541285  
25%                  -0.501860  
50%                  -0.368159  
75%                   0.086655  
max                  25.431073  
#+end_example
** Feature Selection
   To reduce the dimensionality I'm going to use recursive feature selection and model-based selection.
*** RFECV with Logistic Regression
#+BEGIN_SRC ipython :session futures :results none
estimator = LogisticRegressionCV(n_jobs=-1)
selector = RFECV(estimator, scoring='roc_auc',
                 n_jobs=-1,
                 cv=StratifiedKFold(Futures.folds))
x_train_lr_rfs = selector.fit_transform(x_train, y_train)
x_test_lr_rfs = selector.transform(x_test)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(selector.ranking_)
#+END_SRC

#+RESULTS:
: [1 1 1 1]

It looks like it only discarded preferential attachment.

*** RFECV with Extra Trees

#+BEGIN_SRC ipython :session futures :results none
estimator = ExtraTreesClassifier()
selector = RFECV(estimator, scoring='roc_auc', n_jobs=-1, cv=StratifiedKFold(Futures.folds))
x_train_trees_rfs = selector.fit_transform(x_train, y_train)
x_test_trees_rfs = selector.transform(x_test)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(selector.ranking_)
#+END_SRC

#+RESULTS:
: [1 1 1 1]

Strangely, the Extra Trees Classifier didn't remove any columns...
*** Select Model Logistic Regression
#+BEGIN_SRC ipython :session futures :results none
estimator = LogisticRegressionCV(
    n_jobs=-1, scoring='roc_auc',
    cv=StratifiedKFold(Futures.folds)).fit(x_train,
                                           y_train)
selector = SelectFromModel(estimator, prefit=True)
x_train_lr_sfm = selector.transform(x_train)
x_test_lr_sfm = selector.transform(x_test)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(x_train_lr_sfm.shape)
print(estimator.coef_)
#+END_SRC

#+RESULTS:
: (274750, 1)
: [[ 0.18017936  0.57055489  1.51013455 -0.13024556]]

This was more aggressive, cutting out half the features. It looks like it kept *Jaccard Coefficient* and *Adamic Adar* and got rid of *Resource Allocation* and *Preferential Attachment*.

*** Select Model Extra Trees
#+BEGIN_SRC ipython :session futures :results none
estimator = ExtraTreesClassifier()
estimator.fit(x_train, y_train)
selector = SelectFromModel(estimator, prefit=True)
x_train_trees_fsm = selector.transform(x_train)
x_test_trees_fsm = selector.transform(x_test)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(estimator.feature_importances_)
print(x_train_trees_fsm.shape)
#+END_SRC

#+RESULTS:
: [ 0.1780366   0.23649471  0.42157419  0.16389449]
: (274750, 1)

This seems much too aggressive, keeping only the *Adamic Adar* feature... But maybe that's all you need, we'll see.

* Fitting the Models
#+BEGIN_SRC ipython :session futures :results none
def fit_and_print(estimator, x_train, x_test):
    """fits the estimator to the data

    Args:
     estimator: model to fit
     x_train: scaled data to fit model to
     x_test: data to test the model with

    Returns:
     tuple: model fit to the data, test score
    """
    model = estimator.fit(x_train, y_train)
    test_score = model.score(x_test, y_test)
    print("Mean Cross-Validation Score: {:.2f}".format(model.scores_[1].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return model, test_score
#+END_SRC
** Logistic Regression
*** Logistic Regression with Recursive Feature Selection
#+BEGIN_SRC ipython :session futures :results output
outcomes = []
logistic_model = LogisticRegressionCV(n_jobs=-1, scoring="roc_auc",
                                      solver='liblinear',
                                      cv=StratifiedKFold(Futures.folds))
logistic_lr_rfs, score = fit_and_print(logistic_model, x_train_lr_rfs, x_test_lr_rfs)
outcomes.append((score, "logistic LR RFS"))
#+END_SRC

#+RESULTS:
: Mean Cross-Validation Score: 0.91
: Testing Score: 0.96

*** Logistic Regression with Model Feature Selection
#+BEGIN_SRC ipython :session futures :results output
logistic_lr_mfs, score = fit_and_print(logistic_model, x_train_lr_sfm, x_test_lr_sfm)
outcomes.append((score, "logistic LR SFM"))
#+END_SRC

#+RESULTS:
: Mean Cross-Validation Score: 0.91
: Testing Score: 0.96

*** Extra Trees with Model Feature Selection
#+BEGIN_SRC ipython :session futures :results output
logistic_trees_mfs, score = fit_and_print(logistic_model, x_train_trees_fsm, x_test_trees_fsm)
outcomes.append((score, "Logistic Trees FSM"))
#+END_SRC

#+RESULTS:
: Mean Cross-Validation Score: 0.91
: Testing Score: 0.96

*** Extra Trees with Recursive Feature Selection
#+BEGIN_SRC ipython :session futures :results output
logistic_trees_rfs, scores = fit_and_print(logistic_model, x_train_trees_rfs, x_test_trees_rfs)
outcomes.append((score, "Logistic Trees RFS"))
#+END_SRC

#+RESULTS:
: Mean Cross-Validation Score: 0.91
: Testing Score: 0.96

It doesn't look like any of them really did better than any other.
*** Best Logistic Regression Model
#+BEGIN_SRC ipython :session futures :results output
print(max(outcomes))
#+END_SRC

#+RESULTS:
: (0.95812587351502443, 'logistic LR RFS')

** Fit Grid Search
   Since the Logistic Regression had its own cross-validation I didn't use a grid search, but for the forests I'll use one to figure out the best number of estimators. I'll have to look into what the other parameters do to figure out whether they're going to be useful.

#+BEGIN_SRC ipython :session futures :results none
def fit_grid_search(estimator, parameters, x_train, x_test):
    """Fits the estimator using grid search

    Args:
     estimator: Model to fit
     parameters (dict): hyper-parameters for the grid search
     x_train (array): the training data input
     x_test (array): data to evaluate the best model with

    Returns: 
     tuple: Best Model, best model score
    """
    search = GridSearchCV(estimator, parameters, n_jobs=-1, scoring='roc_auc',
                          cv=StratifiedKFold(Futures.folds))
    search.fit(x_train, y_train)
    best_model = search.best_estimator_
    test_score = best_model.score(x_test, y_test)
    print("Mean of Mean Cross-Validation Scores: {:.2f}".format(search.cv_results_["mean_train_score"].mean()))
    print("Mean of Cross-Validation Score STDs: {:.2f}".format(search.cv_results_["std_train_score"].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return best_model, test_score
#+END_SRC
** Random Forests
#+BEGIN_SRC ipython :session futures :results none
parameters = dict(n_estimators = list(range(10, 200, 10)))
forest = RandomForestClassifier()
forest_outcomes = []
#+END_SRC
*** Logistic Regression with Recursive Feature Selection
#+BEGIN_SRC ipython :session futures :results output
random_forest_lr_rfs, score = fit_grid_search(forest, parameters, x_train_lr_rfs, x_test_lr_rfs)
forest_outcomes.append((score, "Random Forest, LR RFS"))
#+END_SRC

#+RESULTS:
: Mean of Mean Cross-Validation Scores: 0.97
: Mean of Cross-Validation Score STDs: 0.00
: Testing Score: 0.96

*** Logistic Regression with Model Feature Selection
#+BEGIN_SRC ipython :session futures :results output
random_forest_lr_sfm, score = fit_grid_search(forest, parameters, x_train_lr_sfm, x_test_lr_sfm)
forest_outcomes.append((score, "Random Forest, LR MFS"))
#+END_SRC

#+RESULTS:
: Mean of Mean Cross-Validation Scores: 0.94
: Mean of Cross-Validation Score STDs: 0.00
: Testing Score: 0.94

*** Extra Trees with Model Feature Selection
*** Extra Trees with Recursive Feature Selection
** Extra Trees
*** Logistic Regression with Recursive Feature Selection
*** Logistic Regression with Model Feature Selection
*** Extra Trees with Model Feature Selection
*** Extra Trees with Recursive Feature Selection
