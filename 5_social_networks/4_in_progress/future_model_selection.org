#+TITLE: Predicting Future Connections

This will select a model to predict whether an edge in the email-network that currently doesn't have an edge will have one in the future.

* Imports

#+BEGIN_SRC ipython :session futures :results none 
# python standard library
import pickle

# pypi
import networkx
import pandas
import seaborn

from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
    )
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV,
    StratifiedKFold,
    )
from sklearn.preprocessing import StandardScaler
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none 
% matplotlib inline
seaborn.set_style("whitegrid")
#+END_SRC

* Constants

#+BEGIN_SRC ipython :session futures :results none
class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
class Files(object):
    """File-names for data persistence"""
    future_training_data = 'future_training_data.csv'
    future_selection_outcomes = 'future_selection_outcomes.pkl'
    future_model_selection = "future_model_cvs.pkl"
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
class Training(object):
    """data-pickles"""
    x_train_lr_rfs = "x_train_lr_rfs.pkl"
    x_test_lr_rfs = "x_test_lr_rfs.pkl"
    x_train_trees_rfs = "x_train_trees_rfs.pkl"
    x_test_trees_rfs = "x_test_trees_rfs.pkl"
    x_train_lr_sfm = "x_train_lr_sfm.pkl"
    x_test_lr_sfm = "x_test_lr_sfm.pkl"
    x_train_trees_fsm = "x_train_trees_fsm.pkl"
    x_test_trees_fsm = "x_test_trees_fsm.pkl"
#+END_SRC

* The Email-Graph
  To get the features for the models we'll need to use the email-graph.

#+BEGIN_SRC ipython :session futures :results none
email = networkx.read_gpickle(Futures.graph_file)
#+END_SRC

* The Data

** The Given Data 
   We're given a csv file with the training and prediction data in it ('Future_Connections.csv').
#+BEGIN_SRC sh
head Future_Connections.csv
echo
#+END_SRC

#+RESULTS:
|            | Future Connection |
| (6, 840)   |               0.0 |
| (4, 197)   |               0.0 |
| (620, 979) |               0.0 |
| (519, 872) |               0.0 |
| (382, 423) |               0.0 |
| (97, 226)  |               1.0 |
| (349, 905) |               0.0 |
| (429, 860) |               0.0 |
| (309, 989) |               0.0 |

Org-mode converted it to a table, but it's actually a CSV. The first line of data looks like this.

#+BEGIN_EXAMPLE
"(6, 840)",0.0
#+END_EXAMPLE


#+BEGIN_SRC ipython :session futures :results none
future_connections_pre_loaded = os.path.isfile(Files.future_training_data)
if future_connections_pre_loaded:
    future_connections = pandas.read_csv(Files.future_training_data,
                                         index_col=0)
else:
    future_connections = pandas.read_csv(Futures.data_file,
                                         index_col=0,
                                         converters={0: eval})
#+END_SRC

So, we're loading the node-pairs (edges) as the index of the data-frame and explicitly telling pandas that the Future Connection values should be converted , which I don't think is necessary, but this came with the problem statement so I'll just leave it in in case there's some side-effect I'm not aware of.

#+BEGIN_SRC ipython :session futures :results output
print(future_connections[Futures.target].value_counts())
#+END_SRC

#+RESULTS:
: 0.0    337002
: 1.0     29332
: Name: Future Connection, dtype: int64

This is a fairly big (and lopsided) data-set.

#+BEGIN_SRC ipython :session futures :file /tmp/future_connections_counts.png
seaborn.countplot(x=Futures.target, data=future_connections)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_connections_counts.png]]

* Adding networkx features
   To create features to train the model and make predictions, I'm going to use the networkx [[https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.link_prediction.html][link prediction]] algorithms.

** Add Networkx Data
   This is a function to get networkx data and add it to the data-frame. It won't work for the community-based algorithms.

#+BEGIN_SRC ipython :session futures :results none
def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
                   for output in adder(graph, frame.index)]
    return frame
#+END_SRC

** Adding A Resource Allocation Index

#+BEGIN_SRC ipython :session futures :results none
if not future_connections_pre_loaded:
    add_networkx_data(networkx.resource_allocation_index,
                      DataNames.resource_allocation)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  preferential_attachment  
: (6, 840)     2.110314                     2070  

** Adding the Jaccard Coefficient
#+BEGIN_SRC ipython :session futures :results none
if not future_connections_pre_loaded:
    add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  preferential_attachment  
: (6, 840)     2.110314                     2070  

** Adamic Adar

#+BEGIN_SRC ipython :session futures :results none
if not future_connections_pre_loaded:
    add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  preferential_attachment  
: (6, 840)     2.110314                     2070  

** Preferential Attachment
#+BEGIN_SRC ipython :session futures :results none
if not future_connections_pre_loaded:
    add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  preferential_attachment  
: (6, 840)     2.110314                     2070  

** Community-Based Link Prediction
   This requires identifying 'communities' first, so I'll defer it for now.
#+BEGIN_SRC ipython :session futures :results none
#add_networkx_data(networkx.cn_soundarajan_hopcroft, DataNames.common_neighbors)
#+END_SRC

These three all require communities for them to work (so I'm skipping them):
   - cn_soundarajan_hopcroft
   - ra_index_soundarajan_hopcroft
   - within_inter_cluster

** Saving the Data

#+BEGIN_SRC ipython :session futures :results none
future_connections.to_csv(Files.future_training_data)
#+END_SRC

* Setup the Training and Testing Data
** Separating the Edges Without 'Future Connection' Values
   We are going to train on the values in the data with predictions and then make predictions for those that don't. For model selection we don't need the set missing predictions, but I'll separate it out anyway to be complete.

#+BEGIN_SRC ipython :session futures :results none
prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
#+END_SRC

#+RESULTS:
: (122112, 5)
: (366334, 5)

** Separate the Target and Training Sets
#+BEGIN_SRC ipython :session futures :results none
non_target = [column for column in future_connections.columns
              if column != Futures.target]
training = training_set[non_target]
testing = training_set[Futures.target]
predictions = prediction_set[non_target]
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
assert all(training.columns == predictions.columns)
assert len(training) == len(testing)
#+END_SRC

** Setting Up the Testing and Training Sets
#+BEGIN_SRC ipython :session futures :results none
x_train, x_test, y_train, y_test = train_test_split(training, testing, stratify=testing)
#+END_SRC

#+BEGIN_SRC ipython :session futures :file /tmp/future_training.png
seaborn.countplot(y_train)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_training.png]]

#+BEGIN_SRC ipython :session futures :file /tmp/future_testing.png
seaborn.countplot(y_test)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_testing.png]]

** Scaling the Data
   To enable the use of linear models I'm going to scale the data so the mean is 0 and the variace is 1.

#+BEGIN_SRC ipython :session futures :results none
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

x_train = pandas.DataFrame(x_train, columns=training.columns)
x_test = pandas.DataFrame(x_test, columns=training.columns)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(x_train.describe())
print(x_test.describe())
#+END_SRC

#+RESULTS:
#+begin_example
       resource_allocation  jaccard_coefficient   adamic_adar  \
count         2.747500e+05         2.747500e+05  2.747500e+05   
mean          2.469766e-17         1.624098e-17  2.464594e-17   
std           1.000002e+00         1.000002e+00  1.000002e+00   
min          -3.769493e-01        -5.307056e-01 -4.294212e-01   
25%          -3.769493e-01        -5.307056e-01 -4.294212e-01   
50%          -3.769493e-01        -5.307056e-01 -4.294212e-01   
75%          -7.687495e-02         1.911122e-01  4.706022e-03   
max           6.203408e+01         2.617655e+01  4.460797e+01   

       preferential_attachment  
count             2.747500e+05  
mean             -2.193049e-17  
std               1.000002e+00  
min              -5.433939e-01  
25%              -5.043521e-01  
50%              -3.717248e-01  
75%               7.610766e-02  
max               4.248928e+01  
       resource_allocation  jaccard_coefficient   adamic_adar  \
count         91584.000000         91584.000000  91584.000000   
mean              0.004797             0.002572      0.004604   
std               0.993441             0.981883      0.992989   
min              -0.376949            -0.530706     -0.429421   
25%              -0.376949            -0.530706     -0.429421   
50%              -0.376949            -0.530706     -0.429421   
75%              -0.067455             0.201000      0.012482   
max              48.658618            26.176552     36.434797   

       preferential_attachment  
count             91584.000000  
mean                  0.006888  
std                   1.006287  
min                  -0.543394  
25%                  -0.503204  
50%                  -0.367132  
75%                   0.087160  
max                  42.887739  
#+end_example
** Feature Selection
   To reduce the dimensionality I'm going to use recursive feature selection and model-based selection.

#+BEGIN_SRC ipython :session futures :results none
def pickle_it(thing, name):
    """saves the thing as a pickle"""
    with open(name, "wb") as writer:
        pickle.dump(thing, writer)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
def unpickle_it(name):
    """loads the object from the file-name

    Args:
     name (str): name of binary pickle file

    Returns:
     obj: unpickled object
    """
    with open(name, 'rb') as reader:
        thing = pickle.load(reader)
    return thing
#+END_SRC

*** RFECV with Logistic Regression
#+BEGIN_SRC ipython :session futures :results none
if os.path.isfile(Training.x_train_lr_rfs):
    x_train_lr_rfs = unpickle_it(Training.x_train_lr_rfs)
    x_test_lr_rfs = unpickle_it(Training.x_test_lr_rfs)
else:
    estimator = LogisticRegressionCV(n_jobs=-1)
    selector = RFECV(estimator, scoring='roc_auc',
                     n_jobs=-1,
                     cv=StratifiedKFold(Futures.folds))
    x_train_lr_rfs = selector.fit_transform(x_train, y_train)
    x_test_lr_rfs = selector.transform(x_test)
    pickle_it(x_train_lr_rfs, Training.x_train_lr_rfs)
    pickle_it(x_test_lr_rfs, Training.x_test_lr_rfs)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(selector.ranking_)
#+END_SRC

#+RESULTS:
: [1 1 1 2]

It looks like it only discarded preferential attachment.

*** RFECV with Extra Trees

#+BEGIN_SRC ipython :session futures :results none
if os.path.isfile(Training.x_train_trees_rfs):
    x_train_trees_rfs = unpickle_it(Training.x_train_trees_rfs)
    x_test_trees_rfs = unpickle_it(Training.x_test_trees_rfs)
else:
    estimator = ExtraTreesClassifier()
    selector = RFECV(estimator, scoring='roc_auc', n_jobs=-1, cv=StratifiedKFold(Futures.folds))
    x_train_trees_rfs = selector.fit_transform(x_train, y_train)
    x_test_trees_rfs = selector.transform(x_test)
    pickle_it(x_train_trees_rfs, Training.x_train_trees_rfs)
    pickle_it(x_test_trees_rfs, Training.x_test_trees_rfs)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(selector.ranking_)
#+END_SRC

#+RESULTS:
: [1 1 1 1]

Strangely, the Extra Trees Classifier didn't remove any columns...
*** Select Model Logistic Regression
#+BEGIN_SRC ipython :session futures :results none
if os.path.isfile(Training.x_train_lr_sfm):
    x_train_lr_sfm = unpickle_it(Training.x_train_lr_sfm)
    x_test_lr_sfm = unpickle_it(Training.x_test_lr_sfm)
else:
    estimator = LogisticRegressionCV(
        n_jobs=-1, scoring='roc_auc',
        cv=StratifiedKFold(Futures.folds)).fit(x_train,
                                               y_train)
    selector = SelectFromModel(estimator, prefit=True)
    x_train_lr_sfm = selector.transform(x_train)
    x_test_lr_sfm = selector.transform(x_test)
    pickle_it(x_train_lr_sfm, Training.x_train_lr_sfm)
    pickle_it(x_test_lr_sfm, Training.x_test_lr_sfm)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(x_train_lr_sfm.shape)
print(estimator.coef_)
#+END_SRC

#+RESULTS:
: (274750, 2)
: [[ 0.42103148  0.666706    0.91835965  0.07331099]]

This was more aggressive, cutting out half the features. It looks like it kept *Jaccard Coefficient* and *Adamic Adar* and got rid of *Resource Allocation* and *Preferential Attachment*.

*** Select Model Extra Trees
#+BEGIN_SRC ipython :session futures :results none
if os.path.isfile(Training.x_train_trees_fsm):
    x_train_trees_fsm = unpickle_it(Training.x_train_trees_fsm)
    x_test_trees_fsm = unpickle_it(Training.x_test_trees_fsm)
else:
    estimator = ExtraTreesClassifier()
    estimator.fit(x_train, y_train)
    selector = SelectFromModel(estimator, prefit=True)
    x_train_trees_fsm = selector.transform(x_train)
    x_test_trees_fsm = selector.transform(x_test)
    pickle_it(x_train_trees_fsm, Training.x_train_trees_fsm)
    pickle_it(x_test_trees_fsm, Training.x_test_trees_fsm)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(estimator.feature_importances_)
print(x_train_trees_fsm.shape)
#+END_SRC

#+RESULTS:
: [ 0.22957814  0.26597312  0.29719135  0.20725739]
: (274750, 2)

This seems much too aggressive, keeping only the *Adamic Adar* feature... But maybe that's all you need, we'll see.

* Fitting the Models
** Persistent Storage
   The outcomes will be stored in a set of identifiers and a dict that maps scores to identifiers.
#+BEGIN_SRC ipython :session futures :results none
if os.path.isfile(Files.future_model_selection):
    with open(Files.future_model_section, 'rb') as pkl:
        scores_identifiers = pickle.load(pkl)
        identifiers = set(scores_identifiers.values())
else:
    scores_identifiers = {}
    identifiers = set()
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
def fit_and_print(estimator, x_train, x_test):
    """fits the estimator to the data

    Args:
     estimator: model to fit
     x_train: scaled data to fit model to
     x_test: data to test the model with

    Returns:
     tuple: model fit to the data, test score
    """
    model = estimator.fit(x_train, y_train)
    test_score = model.score(x_test, y_test)
    print("Mean Cross-Validation Score: {:.2f}".format(model.scores_[1].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return model, test_score
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
data_sets = {("extra trees", 'select from model') : (x_train_trees_fsm, x_test_trees_fsm),
             ("extra trees", 'recursive feature selection') : (x_train_trees_rfs, x_test_trees_rfs),
             ('logistic regression', "recursive feature selection") : (x_train_lr_rfs, x_test_lr_rfs),
             ('logistic regression', "select from model") : (x_train_lr_sfm, x_test_lr_sfm)}
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
def fit_and_print_all(model, model_name):
    """Fits the model against all data instances

    Args:
     model: model to fit to the data sets
     model_name: identifier for the outcomes
    """
    for data_set, x in data_sets.items():        
        selector, method = data_set
        train, test = x
        key = ','.join([model_name, selector, method])
        if key not in identifiers:
            print(key)
            fitted, score = fit_and_print(model, train, test)
            scores_identifiers[key] = score
            identifiers.add(key)
        else:
            score = scores_identifiers[key]
            print("{}: {:.2f}".format(key, score))
        print()
    best = max(scores_identifiers)
    print("Best Model So Far: {}, Score={:.2f}".format(best, scores_identifiers[best]))
    with open(Files.future_model_selection, 'wb') as writer:
        pickle.dump(scores_identifiers, writer)
    return
#+END_SRC

** Logistic Regression
#+BEGIN_SRC ipython :session futures :results output
logistic_model = LogisticRegressionCV(n_jobs=-1, scoring="roc_auc",
                                      solver='liblinear',
                                      cv=StratifiedKFold(Futures.folds))
fit_and_print_all(logistic_model, "Logistic Regression")
#+END_SRC

#+RESULTS:
: Logistic Regression,extra trees,select from model: 0.92
: 
: Logistic Regression,extra trees,recursive feature selection: 0.92
: 
: Logistic Regression,logistic regression,select from model: 0.92
: 
: Logistic Regression,logistic regression,recursive feature selection: 0.92
: 
: Best Model So Far: Logistic Regression,logistic regression,select from model, Score=0.92

** Fit Grid Search
   Since the Logistic Regression had its own cross-validation I didn't use a grid search, but for the forests I'll use one to figure out the best number of estimators. I'll have to look into what the other parameters do to figure out whether they're going to be useful.

#+BEGIN_SRC ipython :session futures :results none
def fit_grid_search(estimator, parameters, x_train, x_test):
    """Fits the estimator using grid search

    Args:
     estimator: Model to fit
     parameters (dict): hyper-parameters for the grid search
     x_train (array): the training data input
     x_test (array): data to evaluate the best model with

    Returns: 
     tuple: Best Model, best model score
    """
    search = GridSearchCV(estimator, parameters, n_jobs=-1, scoring='roc_auc',
                          cv=StratifiedKFold(Futures.folds))
    search.fit(x_train, y_train)
    best_model = search.best_estimator_
    test_score = best_model.score(x_test, y_test)
    print("Mean of Mean Cross-Validation Scores: {:.2f}".format(
        search.cv_results_["mean_train_score"].mean()))
    print("Mean of Cross-Validation Score STDs: {:.2f}".format(
        search.cv_results_["std_train_score"].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return best_model, test_score
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
def fit_grid_searches(estimator, parameters, name):
    """Fits the estimator against all the data-sets

    Args:
     estimator: instance of model to test
     parameters: dict of grid-search parameters
     name: identifier for the model
    """
    for data_set, x in data_sets.items():
        selector, method = data_set
        train, test = x
        key = ",".join([name, selector, method])
        if key not in identifiers:
            print(key)
            fitted, score = fit_grid_search(estimator, parameters, train, test)
            scores_identifiers[key] = score
            identifiers.add(key)
        else:
            score = scores_identifiers[key]
            print("{}: {:.2f}".format(key, score))
        print()
    best = max(scores_identifiers)
    print("Best Model So Far: {}, Score={:.2f}".format(best, scores_identifiers[best]))
    with open(Files.future_model_selection, 'wb') as writer:
        pickle.dump(scores_identifiers, writer)
    return
#+END_SRC

** Random Forests
#+BEGIN_SRC ipython :session futures :results none
parameters = dict(n_estimators = list(range(10, 200, 10)))
forest = RandomForestClassifier()
fit_grid_searches(forest, parameters, "Random Forest")
#+END_SRC
** Extra Trees
#+BEGIN_SRC ipython :session futures :results none
parameters = dict(n_estimators = list(range(10, 200, 10)))
trees = ExtraTreesClassifier()
fit_grid_searches(forest, parameters, "Extra Trees")
#+END_SRC
