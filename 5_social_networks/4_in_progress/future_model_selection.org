#+TITLE: Predicting Future Connections

This will select a model to predict whether an edge in the email-network that currently doesn't have an edge will have one in the future.

* Imports

#+BEGIN_SRC ipython :session futures :results none 
# pypi
import networkx
import pandas
import seaborn

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import RFECV
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import (
    train_test_split,
    StratifiedKFold,
    )
from sklearn.preprocessing import StandardScaler
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none 
% matplotlib inline
seaborn.set_style("whitegrid")
#+END_SRC

* Constants

#+BEGIN_SRC ipython :session futures :results none
class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
#+END_SRC

* The Email-Graph
  To get the features for the models we'll need to use the email-graph.

#+BEGIN_SRC ipython :session futures :results none
email = networkx.read_gpickle(Futures.graph_file)
#+END_SRC

* The Data

** The Given Data 
   We're given a csv file with the training and prediction data in it ('Future_Connections.csv').
#+BEGIN_SRC sh
head Future_Connections.csv
echo
#+END_SRC

#+RESULTS:
|            | Future Connection |
| (6, 840)   |               0.0 |
| (4, 197)   |               0.0 |
| (620, 979) |               0.0 |
| (519, 872) |               0.0 |
| (382, 423) |               0.0 |
| (97, 226)  |               1.0 |
| (349, 905) |               0.0 |
| (429, 860) |               0.0 |
| (309, 989) |               0.0 |

Org-mode converted it to a table, but it's actually a CSV. The first line of data looks like this.

#+BEGIN_EXAMPLE
"(6, 840)",0.0
#+END_EXAMPLE


#+BEGIN_SRC ipython :session futures :results none
future_connections = pandas.read_csv(Futures.data_file,
                                     index_col=0,
                                     converters={0: eval})
#+END_SRC

So, we're loading the node-pairs (edges) as the index of the data-frame and explicitly telling pandas that the Future Connection values should be converted , which I don't think is necessary, but this came with the problem statement so I'll just leave it in in case there's some side-effect I'm not aware of.

#+BEGIN_SRC ipython :session futures :results output
print(future_connections[Futures.target].value_counts())
#+END_SRC

#+RESULTS:
: 0.0    337002
: 1.0     29332
: Name: Future Connection, dtype: int64

This is a fairly big (and lopsided) data-set.

#+BEGIN_SRC ipython :session futures :file /tmp/future_connections_counts.png
seaborn.countplot(x=Futures.target, data=future_connections)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_connections_counts.png]]

* Adding networkx features
   To create features to train the model and make predictions, I'm going to use the networkx [[https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.link_prediction.html][link prediction]] algorithms.

** Add Networkx Data
   This is a function to get networkx data and add it to the data-frame. It won't work for the community-based algorithms.

#+BEGIN_SRC ipython :session futures :results none
def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
                   for output in adder(graph, frame.index)]
    return frame
#+END_SRC

** Adding A Resource Allocation Index

#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.resource_allocation_index,
                  DataNames.resource_allocation)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation
: (6, 840)                0.0             0.136721

** Adding the Jaccard Coefficient
#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient
: (6, 840)                0.0             0.136721              0.07377

** Adamic Adar

#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  
: (6, 840)     2.110314  

** Preferential Attachment
#+BEGIN_SRC ipython :session futures :results none
add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(future_connections.head(1))
#+END_SRC

#+RESULTS:
:           Future Connection  resource_allocation  jaccard_coefficient  \
: (6, 840)                0.0             0.136721              0.07377   
: 
:           adamic_adar  preferential_attachment  
: (6, 840)     2.110314                     2070  

** Community-Based Link Prediction
   This requires identifying 'communities' first, so I'll defer it for now.
#+BEGIN_SRC ipython :session futures :results none
#add_networkx_data(networkx.cn_soundarajan_hopcroft, DataNames.common_neighbors)
#+END_SRC

These three all require communities for them to work (so I'm skipping them):
   - cn_soundarajan_hopcroft
   - ra_index_soundarajan_hopcroft
   - within_inter_cluster

* Setup the Training and Testing Data
** Separating the Edges Without 'Future Connection' Values
   We are going to train on the values in the data with predictions and then make predictions for those that don't. For model selection we don't need the set missing predictions, but I'll separate it out anyway to be complete.

#+BEGIN_SRC ipython :session futures :results none
prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
#+END_SRC

#+RESULTS:
: (122112, 5)
: (366334, 5)

** Separate the Target and Training Sets
#+BEGIN_SRC ipython :session futures :results none
non_target = [column for column in future_connections.columns
              if column != Futures.target]
training = training_set[non_target]
testing = training_set[Futures.target]
predictions = prediction_set[non_target]
#+END_SRC

#+BEGIN_SRC ipython :session futures :results none
assert all(training.columns == predictions.columns)
assert len(training) == len(testing)
#+END_SRC

** Setting Up the Testing and Training Sets
#+BEGIN_SRC ipython :session futures :results none
x_train, x_test, y_train, y_test = train_test_split(training, testing, stratify=testing)
#+END_SRC

#+BEGIN_SRC ipython :session futures :file /tmp/future_training.png
seaborn.countplot(y_train)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_training.png]]

#+BEGIN_SRC ipython :session futures :file /tmp/future_testing.png
seaborn.countplot(y_test)
#+END_SRC

#+RESULTS:
[[file:/tmp/future_testing.png]]

** Scaling the Data
   To enable the use of linear models I'm going to scale the data so the mean is 0 and the variace is 1.

#+BEGIN_SRC ipython :session futures :results none
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

x_train = pandas.DataFrame(x_train, columns=training.columns)
x_test = pandas.DataFrame(x_test, columns=training.columns)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(x_train.describe())
print(x_test.describe())
#+END_SRC

#+RESULTS:
#+begin_example
       resource_allocation  jaccard_coefficient   adamic_adar  \
count         2.747500e+05         2.747500e+05  2.747500e+05   
mean         -6.336050e-17        -3.749907e-19 -5.992093e-17   
std           1.000002e+00         1.000002e+00  1.000002e+00   
min          -3.763564e-01        -5.344745e-01 -4.293893e-01   
25%          -3.763564e-01        -5.344745e-01 -4.293893e-01   
50%          -3.763564e-01        -5.344745e-01 -4.293893e-01   
75%          -7.591630e-02         1.919979e-01  4.254655e-03   
max           6.165812e+01         2.634501e+01  4.443639e+01   

       preferential_attachment  
count             2.747500e+05  
mean             -1.779266e-17  
std               1.000002e+00  
min              -5.405228e-01  
25%              -5.013450e-01  
50%              -3.684809e-01  
75%               7.723832e-02  
max               4.241034e+01  
       resource_allocation  jaccard_coefficient   adamic_adar  \
count         91584.000000         91584.000000  91584.000000   
mean             -0.001957             0.001202     -0.001831   
std               0.969007             1.007665      0.977610   
min              -0.376356            -0.534475     -0.429389   
25%              -0.376356            -0.534475     -0.429389   
50%              -0.376356            -0.534475     -0.429389   
75%              -0.078064             0.187122      0.003863   
max              25.480252            26.345006     23.838226   

       preferential_attachment  
count             91584.000000  
mean                 -0.005740  
std                   0.961441  
min                  -0.540523  
25%                  -0.502481  
50%                  -0.370752  
75%                   0.072128  
max                  22.358088  
#+end_example
** Feature Selection
   To reduce the dimensionality I'm going to use recursive feature selection and model-based selection.
*** RFECV with Logistic Regression
#+BEGIN_SRC ipython :session futures :results none
estimator = LogisticRegressionCV(n_jobs=-1)
selector = RFECV(estimator, scoring='roc_auc',
                 n_jobs=-1,
                 cv=StratifiedKFold(Futures.folds))
x_train_lr_rfs = selector.fit_transform(x_train, y_train)
x_test_lr_rfs = selector.transform(x_test)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(selector.ranking_)
#+END_SRC

#+RESULTS:
: [1 1 1 2]

It looks like it only discarded preferential attachment.

*** RFECV with Extra Trees

#+BEGIN_SRC ipython :session futures :results none
estimator = ExtraTreesClassifier()
selector = RFECV(estimator, scoring='roc_auc', n_jobs=-1, cv=StratifiedKFold(Futures.folds))
x_train_trees_rfs = selector.fit_transform(x_train, y_train)
x_test_trees_rfs = selector.transform(x_test)
#+END_SRC

#+BEGIN_SRC ipython :session futures :results output
print(selector.ranking_)
#+END_SRC
