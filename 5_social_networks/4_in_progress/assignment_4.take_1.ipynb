{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-social-network-analysis/resources/yPcBs) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import networkx\n",
    "import pandas\n",
    "import numpy\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.feature_selection import (\n",
    "    RFECV,\n",
    "    SelectFromModel,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 1 - Random Graph Identification\n",
    "\n",
    "For the first part of this assignment you will analyze randomly generated graphs and determine which algorithm created them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "part_one_graphs = pickle.load(open('A4_graphs','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<br>\n",
    "`P1_Graphs` is a list containing 5 networkx graphs. Each of these graphs were generated by one of three possible algorithms:\n",
    "* Preferential Attachment (`'PA'`)\n",
    "* Small World with low probability of rewiring (`'SW_L'`)\n",
    "* Small World with high probability of rewiring (`'SW_H'`)\n",
    "\n",
    "Anaylze each of the 5 graphs and determine which of the three algorithms generated the graph.\n",
    "\n",
    "*The `graph_identification` function should return a list of length 5 where each element in the list is either `'PA'`, `'SW_L'`, or `'SW_H'`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def graph_identification():\n",
    "    \"\"\"Identifies the type of graph each of the graphs is\n",
    "\n",
    "    Returns:\n",
    "     list: string identifiers for the type of graph\n",
    "    \"\"\"\n",
    "    graph_types = []\n",
    "    for graph in part_one_graphs:\n",
    "        path = networkx.average_shortest_path_length(graph)\n",
    "        coefficient = networkx.average_clustering(graph)\n",
    "        if path > 6:\n",
    "            if coefficient < 0.5:\n",
    "                graph_types.append(\"SW_L\")\n",
    "            else:\n",
    "                raise Exception(\"unexpected type\")\n",
    "        else:\n",
    "            if coefficient < 0.5:\n",
    "                graph_types.append(\"PA\")\n",
    "            else:\n",
    "                graph_types.append(\"SW_H\")\n",
    "    return graph_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 2 - Company Emails\n",
    "\n",
    "For the second part of this assignment you will be workking with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.\n",
    "\n",
    "The network also contains the node attributes `Department` and `ManagmentSalary`.\n",
    "\n",
    "`Department` indicates the department in the company which the person belongs to, and `ManagmentSalary` indicates whether that person is receiving a managment position salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1005\n",
      "Number of edges: 16706\n",
      "Average degree:  33.2458\n"
     ]
    }
   ],
   "source": [
    "email = networkx.read_gpickle('email_prediction.txt')\n",
    "print(networkx.info(email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Part 2A - Salary Prediction\n",
    "\n",
    "Using network `G`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a managment position salary.\n",
    "\n",
    "To accomplish this, you will need to create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a managment salary for nodes where `ManagementSalary` is missing.\n",
    "\n",
    "\n",
    "\n",
    "Your predictions will need to be given as the probability that the corresponding employee is receiving a managment position salary.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).\n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.\n",
    "\n",
    "Using your trained classifier, return a series of length 252 with the data being the probability of receiving managment salary, and the index being the node id.\n",
    "\n",
    "    Example:\n",
    "    \n",
    "        1       1.0\n",
    "        2       0.0\n",
    "        5       0.8\n",
    "        8       1.0\n",
    "            ...\n",
    "        996     0.7\n",
    "        1000    0.5\n",
    "        1001    0.0\n",
    "        Length: 252, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class RandomForest(object):\n",
    "    \"\"\"builds the random forest\n",
    "\n",
    "    Args:\n",
    "     x_train(array): data to train on\n",
    "     y_train(array): targets for training\n",
    "     start (int): start value for number of estimators\n",
    "     stop (int): upper value for range of estimators\n",
    "     step (int): increment for range of estimators\n",
    "     folds (int): K-folds for cross-validation    \n",
    "    \"\"\"\n",
    "    def __init__(self, x_train, y_train,\n",
    "                 start=10, stop=100, step=10, folds=10):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "        self.step = step\n",
    "        self.folds = folds\n",
    "        self._parameters = None\n",
    "        self._search = None\n",
    "        self._model = None\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\"parameters for the grid-search\"\"\"\n",
    "        if self._parameters is None:\n",
    "            self._parameters = dict(n_estimators=range(self.start,\n",
    "                                                       self.stop,\n",
    "                                                       self.step))\n",
    "        return self._parameters\n",
    "\n",
    "    @property\n",
    "    def search(self):\n",
    "        \"\"\"fitted grid search to find hyper-parameters\"\"\"\n",
    "        if self._search is None:\n",
    "            self._search = GridSearchCV(RandomForestClassifier(),\n",
    "                                        self.parameters,\n",
    "                                        cv=StratifiedKFold(self.folds),\n",
    "                                        scoring=\"roc_auc\")\n",
    "            self._search.fit(self.x_train, self.y_train)\n",
    "        return self._search\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        \"\"\"best model found by the grid search\"\"\"\n",
    "        if self._model is None:\n",
    "            self._model = self.search.best_estimator_\n",
    "        return self._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \"\"\"loads and transforms the data\n",
    "    Args:\n",
    "     estimators (int): number of trees to use for feature elimination\n",
    "    \"\"\"\n",
    "    def __init__(self, estimators=10):\n",
    "        self.estimators = estimators\n",
    "        self._data = None\n",
    "        self._dummies_data = None\n",
    "        self._training_data = None\n",
    "        self._prediction_data = None\n",
    "        self._non_management = None\n",
    "        self._y_train = None\n",
    "        self._x_train = None\n",
    "        self._x_predict = None\n",
    "        self._scaler = None\n",
    "        self._x_train_scaled = None\n",
    "        self._x_predict_scaled = None\n",
    "        self._eliminator = None\n",
    "        self._x_train_reduced = None\n",
    "        self._x_predict_reduced = None\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\"The initial data\"\"\"\n",
    "        if self._data is None:\n",
    "            data = pandas.DataFrame(index=email.nodes())\n",
    "            data[\"department\"] = pandas.Series(networkx.get_node_attributes(email, \"Department\"))\n",
    "            data[\"management\"] = pandas.Series(networkx.get_node_attributes(email, \"ManagementSalary\"))\n",
    "            data[\"clustering\"] = pandas.Series(networkx.clustering(email))\n",
    "            data[\"degree\"] = pandas.Series(email.degree())\n",
    "            data[\"degree_centrality\"] = pandas.Series(networkx.degree_centrality(email))\n",
    "            data[\"closeness_centrality\"] = pandas.Series(networkx.closeness_centrality(email))\n",
    "            data[\"betweenness_centrality\"] = pandas.Series(networkx.betweenness_centrality(email))\n",
    "            data[\"pagerank\"] = pandas.Series(networkx.pagerank(email))\n",
    "            _, authority = networkx.hits(email)\n",
    "            data[\"authority\"] = pandas.Series(authority)            \n",
    "            self._data = data\n",
    "        return self._data\n",
    "\n",
    "    @property\n",
    "    def dummies_data(self):\n",
    "        \"\"\"one-hot-encoded data\"\"\"\n",
    "        if self._dummies_data is None:\n",
    "            self._dummies_data = pandas.get_dummies(self.data, columns=[\"department\"])\n",
    "        return self._dummies_data\n",
    "\n",
    "    @property\n",
    "    def training_data(self):\n",
    "        \"\"\"data with management information\"\"\"\n",
    "        if self._training_data is None:\n",
    "            self._training_data = self.dummies_data[pandas.notnull(\n",
    "                self.dummies_data.management)]\n",
    "        return self._training_data\n",
    "\n",
    "    @property\n",
    "    def prediction_data(self):\n",
    "        \"\"\"data missing management information\"\"\"\n",
    "        if self._prediction_data is None:\n",
    "            self._prediction_data = self.dummies_data[pandas.isnull(\n",
    "                self.dummies_data.management)]\n",
    "            assert len(self._prediction_data) == 252\n",
    "        return self._prediction_data\n",
    "\n",
    "    @property\n",
    "    def non_management(self):\n",
    "        \"\"\"list of columns minus management\"\"\"\n",
    "        if self._non_management is None:\n",
    "            self._non_management = [\n",
    "                column for column in self.training_data.columns\n",
    "                if column != \"management\"]\n",
    "        return self._non_management\n",
    "\n",
    "    @property\n",
    "    def y_train(self):\n",
    "        \"\"\"target-data for training\"\"\"\n",
    "        if self._y_train is None:\n",
    "            self._y_train = self.training_data.management\n",
    "        return self._y_train\n",
    "\n",
    "    @property\n",
    "    def x_train(self):\n",
    "        \"\"\"data for training\"\"\"\n",
    "        if self._x_train is None:\n",
    "            self._x_train = self.training_data[self.non_management]\n",
    "        return self._x_train\n",
    "\n",
    "    @property\n",
    "    def x_predict(self):\n",
    "        \"\"\"set to make predictions\"\"\"\n",
    "        if self._x_predict is None:\n",
    "            self._x_predict = self.prediction_data[self.non_management]\n",
    "        return self._x_predict\n",
    "\n",
    "    @property\n",
    "    def scaler(self):\n",
    "        \"\"\"standard scaler\"\"\"\n",
    "        if self._scaler is None:\n",
    "            self._scaler = StandardScaler()\n",
    "        return self._scaler\n",
    "\n",
    "    @property\n",
    "    def x_train_scaled(self):\n",
    "        \"\"\"training data scaled to 1 std, 0 mean\"\"\"\n",
    "        if self._x_train_scaled is None:\n",
    "            self._x_train_scaled = self.scaler.fit_transform(self.x_train)\n",
    "        return self._x_train_scaled\n",
    "\n",
    "    @property\n",
    "    def x_predict_scaled(self):\n",
    "        \"\"\"prediction data with mean 0, std 1\n",
    "\n",
    "        The answer requires the index so this is a dataframe\n",
    "        instead of an array\n",
    "\n",
    "        Returns:\n",
    "         pandas.DataFrame: scaled data with index preserved\n",
    "        \"\"\"\n",
    "        if self._x_predict_scaled is None:\n",
    "            self._x_predict_scaled = pandas.DataFrame(\n",
    "                self.scaler.transform(self.x_predict),\n",
    "                index=self.x_predict.index)\n",
    "        return self._x_predict_scaled\n",
    "\n",
    "    @property\n",
    "    def eliminator(self):\n",
    "        \"\"\"recursive feature eliminator\"\"\"\n",
    "        if self._eliminator is None:\n",
    "            trees = ExtraTreesClassifier(n_estimators=10)\n",
    "            self._eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), \n",
    "                                     scoring=\"roc_auc\")\n",
    "            self._eliminator.fit(self.x_train_scaled, self.y_train)\n",
    "        return self._eliminator\n",
    "\n",
    "    @property\n",
    "    def x_train_reduced(self):\n",
    "        \"\"\"training data with features eliminated\"\"\"\n",
    "        if self._x_train_reduced is None:\n",
    "            self._x_train_reduced = self.eliminator.transform(\n",
    "                self.x_train_scaled)\n",
    "        return self._x_train_reduced\n",
    "\n",
    "    @property\n",
    "    def x_predict_reduced(self):\n",
    "        \"\"\"prediction data with features eliminated\"\"\"\n",
    "        if self._x_predict_reduced is None:\n",
    "            self._x_predict_reduced = pandas.DataFrame(\n",
    "                self.eliminator.transform(self.x_predict_scaled),\n",
    "                index=self.x_predict_scaled.index)\n",
    "        return self._x_predict_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def salary_predictions():\n",
    "    data = DataLoader()\n",
    "    forest = RandomForest(data.x_train_reduced, data.y_train)\n",
    "    probabilities = forest.model.predict_proba(data.x_predict_reduced)\n",
    "    return pandas.Series(probabilities[:, 1], index=data.x_predict_reduced.index)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Part 2B - New Connections Prediction\n",
    "\n",
    "For the last part of this assignment, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future_connections`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Future Connection\n(6, 840)                  0.0\n(4, 197)                  0.0\n(620, 979)                0.0\n(519, 872)                0.0\n(382, 423)                0.0\n(97, 226)                 1.0\n(349, 905)                0.0\n(429, 860)                0.0\n(309, 989)                0.0\n(468, 880)                0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_connections = pandas.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})\n",
    "future_connections.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using network `G` and `future_connections`, identify the edges in `future_connections` with missing values and predict whether or not these edges will have a future connection.\n",
    "\n",
    "To accomplish this, you will need to create a matrix of features for the edges found in `future_connections` using networkx, train a sklearn classifier on those edges in `future_connections` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future_connections` where `Future Connection` is missing.\n",
    "\n",
    "\n",
    "\n",
    "Your predictions will need to be given as the probability of the corresponding edge being a future connection.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).\n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.\n",
    "\n",
    "Using your trained classifier, return a series of length 122112 with the data being the probability of the edge being a future connection, and the index being the edge as represented by a tuple of nodes.\n",
    "\n",
    "    Example:\n",
    "    \n",
    "        (107, 348)    0.35\n",
    "        (542, 751)    0.40\n",
    "        (20, 426)     0.55\n",
    "        (50, 989)     0.35\n",
    "                  ...\n",
    "        (939, 940)    0.15\n",
    "        (555, 905)    0.35\n",
    "        (75, 101)     0.65\n",
    "        Length: 122112, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Futures(object):\n",
    "    target = \"Future Connection\"\n",
    "    data_file = \"Future_Connections.csv\"\n",
    "    graph_file = \"email_prediction.txt\"\n",
    "    networkx_data_index = 2\n",
    "    folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class DataNames(object):\n",
    "    resource_allocation = 'resource_allocation'\n",
    "    jaccard = 'jaccard_coefficient'\n",
    "    adamic = \"adamic_adar\"\n",
    "    preferential = \"preferential_attachment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def add_networkx_data(adder, name, graph=email, frame=future_connections):\n",
    "    \"\"\"Adds networkx data to the frame\n",
    "\n",
    "    The networkx link-prediction functions return generators of triples:\n",
    "     (first-node, second-node, value)\n",
    "\n",
    "    This will use the index of the frame that's passed in as the source of \n",
    "    node-pairs for the networkx function (called `ebunch` in the networkx\n",
    "    documentation) and the add only the value we want back to the frame\n",
    "\n",
    "    Args:\n",
    "     adder: networkx function to call to get the new data\n",
    "     name: column-name to add to the frame\n",
    "     graph: networkx graph to pass to the function\n",
    "     frame (pandas.DataFrame): frame with node-pairs as index to add data to\n",
    "    \"\"\"\n",
    "    frame[name] = [output[Futures.networkx_data_index]\n",
    "                   for output in adder(graph, frame.index)]\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "future_connections = add_networkx_data(networkx.resource_allocation_index,\n",
    "                                       DataNames.resource_allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "future_connections = add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "future_connections = add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "future_connections = add_networkx_data(networkx.preferential_attachment, DataNames.preferential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "prediction_set = future_connections[future_connections[Futures.target].isnull()]\n",
    "training_set = future_connections[future_connections[Futures.target].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert len(prediction_set) + len(training_set) == len(future_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "non_target = [column for column in future_connections.columns\n",
    "              if column != Futures.target]\n",
    "x_train = training_set[non_target]\n",
    "y_train = training_set[Futures.target]\n",
    "x_predict = prediction_set[non_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert all(x_train.columns == x_predict.columns)\n",
    "assert len(x_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_predict_scaled = scaler.transform(x_predict)\n",
    "\n",
    "x_train_frame = pandas.DataFrame(x_train_scaled, columns=x_train.columns)\n",
    "x_predict_frame = pandas.DataFrame(x_predict_scaled, columns=x_predict.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "estimator = ExtraTreesClassifier()\n",
    "estimator.fit(x_train_scaled, y_train)\n",
    "selector = SelectFromModel(estimator, prefit=True)\n",
    "x_train_trees_sfm = selector.transform(x_train_scaled)\n",
    "x_predict_sfm = selector.transform(x_predict_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None,\n           cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n           dual=False, fit_intercept=True, intercept_scaling=1.0,\n           max_iter=100, multi_class='ovr', n_jobs=-1, penalty='l2',\n           random_state=None, refit=True, scoring='roc_auc',\n           solver='liblinear', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegressionCV(n_jobs=-1, scoring='roc_auc', solver='liblinear',\n",
    "                             cv=StratifiedKFold())\n",
    "model.fit(x_train_trees_sfm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def new_connections_predictions():\n",
    "    probabilities = model.predict_proba(x_predict_sfm)\n",
    "    return pandas.Series(probabilities[:, 1], index=prediction_set.index)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "BGNwe",
   "launcher_item_id": "rMoj0",
   "part_id": "E2zRG"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "assignment_4.take_1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
