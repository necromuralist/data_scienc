<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Data Science With Python (Posts about text nltk nlp)</title><link>https://necromuralist.github.io/data_science/</link><description></description><atom:link type="application/rss+xml" rel="self" href="https://necromuralist.github.io/data_science/categories/text-nltk-nlp.xml"></atom:link><language>en</language><copyright>Contents Â© 2017 &lt;a href="mailto:necromuralist@gmail.com"&gt;necromuralist&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sat, 12 Aug 2017 22:08:03 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Assignment 2 - Introduction to NLTK</title><link>https://necromuralist.github.io/data_science/posts/assignment-2-introduction-to-nltk/</link><dc:creator>hades</dc:creator><description>&lt;div&gt;&lt;p&gt;In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling.&lt;/p&gt;
&lt;div class="section" id="part-1-analyzing-moby-dick"&gt;
&lt;h2&gt;1 Part 1 - Analyzing Moby Dick&lt;/h2&gt;
&lt;div class="section" id="imports-and-data-set-up"&gt;
&lt;h3&gt;1.1 Imports and Data Set Up&lt;/h3&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.probability&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-3"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.tokenize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-4"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-5"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pyplot&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-6"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-7"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk.data&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-8"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numba&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-9"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-10"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;a name="rest_code_c74100f19bb545d2ad9b5777c1ed3bb9-11"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_8cf613fd9a274ebc9446b5c05a533481-1"&gt;&lt;/a&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;a name="rest_code_8cf613fd9a274ebc9446b5c05a533481-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;If you would like to work with the raw text you can use 'moby_raw'.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_eea973cd9fb546c79bbcff91dce3dca1-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'moby.txt'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_eea973cd9fb546c79bbcff91dce3dca1-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;moby_raw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;If you would like to work with the novel in &lt;tt class="docutils literal"&gt;nltk.Text&lt;/tt&gt; format you can use 'text1'.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_bcef0d8d58ee4e0da0182473a52ac758-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bcef0d8d58ee4e0da0182473a52ac758-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bcef0d8d58ee4e0da0182473a52ac758-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="examples"&gt;
&lt;h3&gt;1.2 Examples&lt;/h3&gt;
&lt;div class="section" id="example-1"&gt;
&lt;h4&gt;1.2.1 Example 1&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;How many tokens (words and punctuation symbols) are in text1?&lt;/em&gt; A &lt;strong&gt;token&lt;/strong&gt; is a linguistic unit such as a word, punctuation mark, or alpha-numeric strings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_one&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-2"&gt;&lt;/a&gt;     &lt;span class="sd"&gt;"""counts the tokens in moby dick&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     Returns:&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;      int: number of tokens in moby dick&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     """&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-7"&gt;&lt;/a&gt;     &lt;span class="c1"&gt;# or alternatively len(text1)&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-8"&gt;&lt;/a&gt;     &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_one&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} tokens."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_63cf73aa5b1c4eccb162a7797f6800be-12"&gt;&lt;/a&gt;     &lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 254,989 tokens.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="example-2"&gt;
&lt;h4&gt;1.2.2 Example 2&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;How many unique tokens (unique words and punctuation) does text1 have?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_two&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""counts the unique tokens&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     int: count of unique tokens in Moby Dick&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-7"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# or alternatively len(set(text1))&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_UNIQUE_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_two&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} unique tokens."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_d22e64f2af394019bc8a3168c2b66690-12"&gt;&lt;/a&gt;    &lt;span class="n"&gt;MOBY_UNIQUE_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 20,755 unique tokens.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="example-3"&gt;
&lt;h4&gt;1.2.3 Example 3&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;After lemmatizing the verbs, how many unique tokens does text1 have?&lt;/em&gt; A &lt;strong&gt;lemma&lt;/strong&gt; is the canonical form. e.g. &lt;em&gt;run&lt;/em&gt; is the lemma for &lt;em&gt;runs&lt;/em&gt;, &lt;em&gt;ran&lt;/em&gt;, &lt;em&gt;running&lt;/em&gt;, and &lt;em&gt;run&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_three&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Counts the number of lemma in Moby Dick&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     int: count of unique lemma&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;lemmatizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;lemmatizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'v'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;text1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_LEMMA_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_three&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} lemma (found in WordNet)."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_6afa5011e75842d780adeb8c174cee4d-12"&gt;&lt;/a&gt;    &lt;span class="n"&gt;MOBY_LEMMA_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 16,900 lemma (found in WordNet).
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="questions"&gt;
&lt;h3&gt;1.3 Questions&lt;/h3&gt;
&lt;div class="section" id="question-1"&gt;
&lt;h4&gt;1.3.1 Question 1&lt;/h4&gt;
&lt;p&gt;What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-1"&gt;&lt;/a&gt;&lt;span class="nd"&gt;@jit&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;lexical_diversity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-3"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Calculates the lexical diversity of a list of tokens&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: fraction of tokens that are unique&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_a176b49f5e044f42b816c57e592f0f46-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_one&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Calculates the lexical diversity of Moby Dick&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: fraction of tokens that are unique&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lexical_diversity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_one&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_ad0d21f7475d44a0966f7636ae8edd96-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Lexical Diversity of Moby Dick: {:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Lexical Diversity of Moby Dick: 0.08
&lt;/pre&gt;
&lt;p&gt;About 8 percent of the tokens in Moby Dick are unique.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-2"&gt;
&lt;h4&gt;1.3.2 Question 2&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What percentage of tokens is 'whale'or 'Whale'?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_a5fdbed8ce7a46fe911642650986c904-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_frequencies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_two&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""calculates percentage of tokens that are 'whale'&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: percentage of entries that are whales&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;whales&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"whale"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Whale"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;whales&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;whale_fraction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_two&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_f97643c0a31b4fdba83409e04f96f62d-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Percentage of tokens that are whales: {:.2f} %"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;whale_fraction&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Percentage of tokens that are whales: 0.41 %
&lt;/pre&gt;
&lt;p&gt;Around 1 percent of the tokens are 'whale'.&lt;/p&gt;
&lt;p&gt;I originally made two mistakes with this question, I was returning a fraction, not a percentage, and I was using a regular expression &lt;em&gt;'([Ww]hale)'&lt;/em&gt; which I later realized would match &lt;em&gt;whales&lt;/em&gt;, &lt;em&gt;whaler&lt;/em&gt;, and other variants.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
782
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-3"&gt;
&lt;h4&gt;1.3.3 Question 3&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_three&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds 20 most requently occuring tokens&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: (token, frequency) for top 20 tokens&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_57cbaa599d554239a90b669f5af6334a-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_three&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
[(',', 19204), ('the', 13715), ('.', 7308), ('of', 6513), ('and', 6010), ('a', 4545), ('to', 4515), (';', 4173), ('in', 3908), ('that', 2978), ('his', 2459), ('it', 2196), ('I', 2097), ('!', 1767), ('is', 1722), ('--', 1713), ('with', 1659), ('he', 1658), ('was', 1639), ('as', 1620)]
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-4"&gt;
&lt;h4&gt;1.3.4 Question 4&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What tokens have a length of greater than 5 and frequency of more than 150?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_cafd890a1d764e14954df161db5c1fff-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;a name="rest_code_cafd890a1d764e14954df161db5c1fff-2"&gt;&lt;/a&gt;                                        &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"token"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"frequency"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_four&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets tokens with length &amp;gt; 5, frequency &amp;gt; 150"""&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;frame&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-4"&gt;&lt;/a&gt;                                  &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_four&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_267fcf6987a2478d934e315d62dcae8e-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['Captain', 'Pequod', 'Queequeg', 'Starbuck', 'almost', 'before', 'himself', 'little', 'seemed', 'should', 'though', 'through', 'whales', 'without']
&lt;/pre&gt;
&lt;p&gt;I was originally returning the data frame, not just the sorted tokens, which was of course marked wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-5"&gt;
&lt;h4&gt;1.3.5 Question 5&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Find the longest word in text1 and that word's length.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a tuple `(longest_word, length)`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_five&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds the longest word and its length&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Return:&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     tuple: (longest-word, length)&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;longest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extractall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"(?P&amp;lt;long&amp;gt;.{{{}}})"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;long&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_4f625bb4f7a141efa6a7cd02394adc56-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_five&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
("twelve-o'clock-at-night", 23)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-6"&gt;
&lt;h4&gt;1.3.6 Question 6&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What unique words have a frequency of more than 2000? What is their frequency?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_2fd682584bc44b1788a3acdc9bbf5d16-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isalpha&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_six&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Finds words wih frequency &amp;gt; 2000&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: frequency, word tuples&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;common&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;2000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_43fbff370fdf4243860039539a98c6af-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_six&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
[(13715, 'the'), (6513, 'of'), (6010, 'and'), (4545, 'a'), (4515, 'to'), (3908, 'in'), (2978, 'that'), (2459, 'his'), (2196, 'it'), (2097, 'I')]
&lt;/pre&gt;
&lt;p&gt;When I first submitted this I got it wrong because I was returning a list of &lt;tt class="docutils literal"&gt;(word, frequency)&lt;/tt&gt;, not &lt;tt class="docutils literal"&gt;(frequency, word)&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-7"&gt;
&lt;h4&gt;1.3.7 Question 7&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What is the average number of tokens per sentence?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_seven&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""average number of tokens per sentence"""&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_seven&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_82be1908ef5c48a293e2fe447bdcbd41-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Average number of tokens per sentence: {:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Average number of tokens per sentence: 25.88
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-8"&gt;
&lt;h4&gt;1.3.8 Question 8&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What are the 5 most frequent parts of speech in this text? What is their frequency?&lt;/em&gt; Parts of Speech (POS) are the lexical categories that words belong to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_eight&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the 5 most frequent parts of speech&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list (Tuple): (part of speech, frequency) for top 5&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;tags&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;frequencies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_eight&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_3fc451db2ce44923aece491628575eb5-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Top 5 parts of speech: {}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Top 5 parts of speech: [('NN', 4016), ('NNP', 2916), ('JJ', 2875), ('NNS', 2452), ('VBD', 1421)]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-2-spelling-recommender"&gt;
&lt;h2&gt;2 Part 2 - Spelling Recommender&lt;/h2&gt;
&lt;p&gt;For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.&lt;/p&gt;
&lt;p&gt;For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Each of the three different recommenders will use a different distance measure (outlined below)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.metrics.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;edit_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;jaccard_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_849af71608254b24a023bd813d5ce50a-6"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.util&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ngrams&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_cbb722dd9c0540b1b5efa8747df55e25-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;correct_spellings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_cbb722dd9c0540b1b5efa8747df55e25-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;spellings_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;correct_spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;div class="section" id="question-9"&gt;
&lt;h3&gt;2.1 Question 9&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;`Jaccard distance &amp;lt;https://en.wikipedia.org/wiki/Jaccard_index&amp;gt;`_ on the trigrams of the two words.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three: `['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""find the closet words to each entry&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries: collection of words to match&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     gram_number: number of n-grams to use&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: words with the closest jaccard distance to entries&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-10"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-11"&gt;&lt;/a&gt;    &lt;span class="n"&gt;outcomes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;spellings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;spellings_series&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;spellings_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-14"&gt;&lt;/a&gt;        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;jaccard_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ngrams&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-15"&gt;&lt;/a&gt;                                       &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ngrams&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-16"&gt;&lt;/a&gt;                     &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-17"&gt;&lt;/a&gt;        &lt;span class="n"&gt;closest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;outcomes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;closest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_53146eb25ece4278ae496589983040ea-19"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;outcomes&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_nine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds the closest word based on jaccard distance"""&lt;/span&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_b03212b7590a4339a55689de2f924fc8-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_nine&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['corpulent', 'indecence', 'validate']
&lt;/pre&gt;
&lt;p&gt;I originally got both the Jaccard Distance problems wrong because I was just using the distance, not filtering the candidates by the first letter, which turns out to return fairly dissimilar words.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-10"&gt;
&lt;h3&gt;2.2 Question 10&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;`Jaccard distance &amp;lt;https://en.wikipedia.org/wiki/Jaccard_index&amp;gt;`_ on the 4-grams of the two words.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three: `['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_7a6050837b6343da920357d572350313-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_ten&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the neares words using jaccard-distance with 4-grams&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries (list): words to find nearest other word for&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: nearest words found&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_7a6050837b6343da920357d572350313-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_ten&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['cormus', 'incendiary', 'valid']
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-11"&gt;
&lt;h3&gt;2.3 Question 11&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;**`Edit (Levenshtein) distance on the two words with transpositions. &amp;lt;https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance&amp;gt;`_**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three: `['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_eleven&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the nearest words based on Levenshtein distance&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries (list[str]): words to find closest words to&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list[str]: nearest words to the entries&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;outcomes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-12"&gt;&lt;/a&gt;        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;edit_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-13"&gt;&lt;/a&gt;                                    &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-14"&gt;&lt;/a&gt;                     &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;correct_spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-15"&gt;&lt;/a&gt;        &lt;span class="n"&gt;closest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-16"&gt;&lt;/a&gt;        &lt;span class="n"&gt;outcomes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;closest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;outcomes&lt;/span&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_b852ce5b341f4df4aa7602b76e6ccb38-19"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_eleven&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['corpulent', 'intendence', 'validate']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="sources"&gt;
&lt;h2&gt;3 Sources&lt;/h2&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>text nltk nlp</category><guid>https://necromuralist.github.io/data_science/posts/assignment-2-introduction-to-nltk/</guid><pubDate>Sat, 12 Aug 2017 22:02:00 GMT</pubDate></item></channel></rss>