<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Data Science With Python (Posts about text nltk nlp)</title><link>https://necromuralist.github.io/data_science/</link><description></description><atom:link rel="self" type="application/rss+xml" href="https://necromuralist.github.io/data_science/categories/text-nltk-nlp.xml"></atom:link><language>en</language><copyright>Contents Â© 2017 &lt;a href="mailto:necromuralist@gmail.com"&gt;necromuralist&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sun, 13 Aug 2017 23:31:53 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Assignment 2 - Introduction to NLTK</title><link>https://necromuralist.github.io/data_science/posts/assignment-2-introduction-to-nltk/</link><dc:creator>hades</dc:creator><description>&lt;div&gt;&lt;p&gt;In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling.&lt;/p&gt;
&lt;div class="section" id="part-1-analyzing-moby-dick"&gt;
&lt;h2&gt;1 Part 1 - Analyzing Moby Dick&lt;/h2&gt;
&lt;div class="section" id="imports-and-data-set-up"&gt;
&lt;h3&gt;1.1 Imports and Data Set Up&lt;/h3&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.probability&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.stem&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-3"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.tokenize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-4"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-5"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pyplot&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-6"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-7"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk.data&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-8"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numba&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-9"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-10"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;a name="rest_code_89894ef1e8e44db99e6a71abc511fb2e-11"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_b7f4c0b43f974b02bdfb80251635251c-1"&gt;&lt;/a&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;a name="rest_code_b7f4c0b43f974b02bdfb80251635251c-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;If you would like to work with the raw text you can use 'moby_raw'.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_fc1bf0d0ba65473ab7bc1ddd4f303c5f-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'moby.txt'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_fc1bf0d0ba65473ab7bc1ddd4f303c5f-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;moby_raw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;If you would like to work with the novel in &lt;tt class="docutils literal"&gt;nltk.Text&lt;/tt&gt; format you can use 'text1'.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_8a7c6d96525247de8a5789ac4c21beb1-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8a7c6d96525247de8a5789ac4c21beb1-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8a7c6d96525247de8a5789ac4c21beb1-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="examples"&gt;
&lt;h3&gt;1.2 Examples&lt;/h3&gt;
&lt;div class="section" id="example-1"&gt;
&lt;h4&gt;1.2.1 Example 1&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;How many tokens (words and punctuation symbols) are in text1?&lt;/em&gt; A &lt;strong&gt;token&lt;/strong&gt; is a linguistic unit such as a word, punctuation mark, or alpha-numeric strings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_one&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-2"&gt;&lt;/a&gt;     &lt;span class="sd"&gt;"""counts the tokens in moby dick&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     Returns:&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;      int: number of tokens in moby dick&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     """&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-7"&gt;&lt;/a&gt;     &lt;span class="c1"&gt;# or alternatively len(text1)&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-8"&gt;&lt;/a&gt;     &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_one&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} tokens."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_6aaee2f640b244a68694abafc51f151b-12"&gt;&lt;/a&gt;     &lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 254,989 tokens.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="example-2"&gt;
&lt;h4&gt;1.2.2 Example 2&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;How many unique tokens (unique words and punctuation) does text1 have?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_two&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""counts the unique tokens&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     int: count of unique tokens in Moby Dick&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-7"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# or alternatively len(set(text1))&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_UNIQUE_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_two&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} unique tokens."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_24b4a0bd376b42e5abad36771a569ae8-12"&gt;&lt;/a&gt;    &lt;span class="n"&gt;MOBY_UNIQUE_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 20,755 unique tokens.
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="example-3"&gt;
&lt;h4&gt;1.2.3 Example 3&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;After lemmatizing the verbs, how many unique tokens does text1 have?&lt;/em&gt; A &lt;strong&gt;lemma&lt;/strong&gt; is the canonical form. e.g. &lt;em&gt;run&lt;/em&gt; is the lemma for &lt;em&gt;runs&lt;/em&gt;, &lt;em&gt;ran&lt;/em&gt;, &lt;em&gt;running&lt;/em&gt;, and &lt;em&gt;run&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return an integer.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;example_three&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Counts the number of lemma in Moby Dick&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     int: count of unique lemma&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;lemmatizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;WordNetLemmatizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;lemmatizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lemmatize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;'v'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;text1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;MOBY_LEMMA_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;example_three&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Moby Dick has {:,} lemma (found in WordNet)."&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_2e99db9b8c9e40a0b04eccbe8730bae7-12"&gt;&lt;/a&gt;    &lt;span class="n"&gt;MOBY_LEMMA_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Moby Dick has 16,900 lemma (found in WordNet).
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="questions"&gt;
&lt;h3&gt;1.3 Questions&lt;/h3&gt;
&lt;div class="section" id="question-1"&gt;
&lt;h4&gt;1.3.1 Question 1&lt;/h4&gt;
&lt;p&gt;What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-1"&gt;&lt;/a&gt;&lt;span class="nd"&gt;@jit&lt;/span&gt;
&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;lexical_diversity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-3"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Calculates the lexical diversity of a list of tokens&lt;/span&gt;
&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: fraction of tokens that are unique&lt;/span&gt;
&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_953cde7382604334989394a6f6e16c30-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_one&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Calculates the lexical diversity of Moby Dick&lt;/span&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: fraction of tokens that are unique&lt;/span&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;lexical_diversity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_one&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_ab92a780f9d84c159f79f1e2f1f88280-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Lexical Diversity of Moby Dick: {:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Lexical Diversity of Moby Dick: 0.08
&lt;/pre&gt;
&lt;p&gt;About 8 percent of the tokens in Moby Dick are unique.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-2"&gt;
&lt;h4&gt;1.3.2 Question 2&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What percentage of tokens is 'whale'or 'Whale'?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_e61e89938fd14f8198d33a2144ecd3b0-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_frequencies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_two&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""calculates percentage of tokens that are 'whale'&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     float: percentage of entries that are whales&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;whales&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"whale"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Whale"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;whales&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MOBY_TOKEN_COUNT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;whale_fraction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_two&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_91e336210b6b4631be5378580c2dd24e-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Percentage of tokens that are whales: {:.2f} %"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;whale_fraction&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Percentage of tokens that are whales: 0.41 %
&lt;/pre&gt;
&lt;p&gt;Around 1 percent of the tokens are 'whale'.&lt;/p&gt;
&lt;p&gt;I originally made two mistakes with this question, I was returning a fraction, not a percentage, and I was using a regular expression &lt;em&gt;'([Ww]hale)'&lt;/em&gt; which I later realized would match &lt;em&gt;whales&lt;/em&gt;, &lt;em&gt;whaler&lt;/em&gt;, and other variants.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
782
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-3"&gt;
&lt;h4&gt;1.3.3 Question 3&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_three&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds 20 most requently occuring tokens&lt;/span&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: (token, frequency) for top 20 tokens&lt;/span&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_8df9215976e04d879757587fccbb2313-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_three&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
[(',', 19204), ('the', 13715), ('.', 7308), ('of', 6513), ('and', 6010), ('a', 4545), ('to', 4515), (';', 4173), ('in', 3908), ('that', 2978), ('his', 2459), ('it', 2196), ('I', 2097), ('!', 1767), ('is', 1722), ('--', 1713), ('with', 1659), ('he', 1658), ('was', 1639), ('as', 1620)]
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-4"&gt;
&lt;h4&gt;1.3.4 Question 4&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What tokens have a length of greater than 5 and frequency of more than 150?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_98a78f817e9c414fa18cc8d2a116db65-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;a name="rest_code_98a78f817e9c414fa18cc8d2a116db65-2"&gt;&lt;/a&gt;                                        &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"token"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"frequency"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_four&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets tokens with length &amp;gt; 5, frequency &amp;gt; 150"""&lt;/span&gt;
&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;frame&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-4"&gt;&lt;/a&gt;                                  &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_four&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_338a2db467c341a2bc74d8e2ae540352-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['Captain', 'Pequod', 'Queequeg', 'Starbuck', 'almost', 'before', 'himself', 'little', 'seemed', 'should', 'though', 'through', 'whales', 'without']
&lt;/pre&gt;
&lt;p&gt;I was originally returning the data frame, not just the sorted tokens, which was of course marked wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-5"&gt;
&lt;h4&gt;1.3.5 Question 5&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Find the longest word in text1 and that word's length.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a tuple `(longest_word, length)`.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_five&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds the longest word and its length&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Return:&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     tuple: (longest-word, length)&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;longest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extractall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"(?P&amp;lt;long&amp;gt;.{{{}}})"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;longest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;long&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_d017350420344667a85421aa61dbbafd-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_five&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
("twelve-o'clock-at-night", 23)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-6"&gt;
&lt;h4&gt;1.3.6 Question 6&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What unique words have a frequency of more than 2000? What is their frequency?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_38a29af671314fada3d66cc440160e84-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;moby_frequency_frame&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isalpha&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_six&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""Finds words wih frequency &amp;gt; 2000&lt;/span&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: frequency, word tuples&lt;/span&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;common&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;2000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;common&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_8444bc1b9d87461ea7fdf9ec0104a996-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_six&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
[(13715, 'the'), (6513, 'of'), (6010, 'and'), (4545, 'a'), (4515, 'to'), (3908, 'in'), (2978, 'that'), (2459, 'his'), (2196, 'it'), (2097, 'I')]
&lt;/pre&gt;
&lt;p&gt;When I first submitted this I got it wrong because I was returning a list of &lt;tt class="docutils literal"&gt;(word, frequency)&lt;/tt&gt;, not &lt;tt class="docutils literal"&gt;(frequency, word)&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-7"&gt;
&lt;h4&gt;1.3.7 Question 7&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What is the average number of tokens per sentence?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a float.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_seven&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""average number of tokens per sentence"""&lt;/span&gt;
&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sent_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_raw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;word_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_seven&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_bea4ac4d7e2f4938a821b71c842c58f4-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Average number of tokens per sentence: {:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Average number of tokens per sentence: 25.88
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-8"&gt;
&lt;h4&gt;1.3.8 Question 8&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;What are the 5 most frequent parts of speech in this text? What is their frequency?&lt;/em&gt; Parts of Speech (POS) are the lexical categories that words belong to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_eight&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the 5 most frequent parts of speech&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list (Tuple): (part of speech, frequency) for top 5&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;tags&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;moby_words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;frequencies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FreqDist&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;frequencies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;answer_eight&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_19f22d7ad474405481d7131903d135b8-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Top 5 parts of speech: {}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
Top 5 parts of speech: [('NN', 4016), ('NNP', 2916), ('JJ', 2875), ('NNS', 2452), ('VBD', 1421)]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="part-2-spelling-recommender"&gt;
&lt;h2&gt;2 Part 2 - Spelling Recommender&lt;/h2&gt;
&lt;p&gt;For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.&lt;/p&gt;
&lt;p&gt;For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Each of the three different recommenders will use a different distance measure (outlined below)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_c372ab263f1d45578d94796201db0be8-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;
&lt;a name="rest_code_c372ab263f1d45578d94796201db0be8-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.metrics.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_c372ab263f1d45578d94796201db0be8-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;edit_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c372ab263f1d45578d94796201db0be8-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;jaccard_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c372ab263f1d45578d94796201db0be8-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c372ab263f1d45578d94796201db0be8-6"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.util&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ngrams&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_fa927e815f8b40d89b5f7e83114acda8-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;correct_spellings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_fa927e815f8b40d89b5f7e83114acda8-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;spellings_series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;correct_spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;div class="section" id="question-9"&gt;
&lt;h3&gt;2.1 Question 9&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Jaccard_index"&gt;Jaccard distance&lt;/a&gt; on the trigrams of the two words.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three:&lt;/strong&gt; &lt;tt class="docutils literal"&gt;['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']&lt;/tt&gt;.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""find the closet words to each entry&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries: collection of words to match&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-6"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     gram_number: number of n-grams to use&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: words with the closest jaccard distance to entries&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-10"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-11"&gt;&lt;/a&gt;    &lt;span class="n"&gt;outcomes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;spellings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;spellings_series&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;spellings_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-14"&gt;&lt;/a&gt;        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;jaccard_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ngrams&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-15"&gt;&lt;/a&gt;                                       &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ngrams&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_number&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-16"&gt;&lt;/a&gt;                     &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-17"&gt;&lt;/a&gt;        &lt;span class="n"&gt;closest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;outcomes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;closest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_5803e6005d404a1387f7c85c7a047379-19"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;outcomes&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code ipython"&gt;&lt;a name="rest_code_51620bbdded141b59e1f6155d4f972af-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_nine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_51620bbdded141b59e1f6155d4f972af-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""finds the closest word based on jaccard distance"""&lt;/span&gt;
&lt;a name="rest_code_51620bbdded141b59e1f6155d4f972af-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_51620bbdded141b59e1f6155d4f972af-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_51620bbdded141b59e1f6155d4f972af-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_nine&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['corpulent', 'indecence', 'validate']
&lt;/pre&gt;
&lt;p&gt;I originally got both the Jaccard Distance problems wrong because I was just using the distance, not filtering the candidates by the first letter, which turns out to return fairly dissimilar words.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="question-10"&gt;
&lt;h3&gt;2.2 Question 10&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Jaccard_index"&gt;Jaccard distance&lt;/a&gt; on the 4-grams of the two words.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three:&lt;/strong&gt; &lt;tt class="docutils literal"&gt;['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']&lt;/tt&gt;.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_ten&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the neares words using jaccard-distance with 4-grams&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries (list): words to find nearest other word for&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list: nearest words found&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_4073effe606d4bc4a1804ba777d0fea3-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_ten&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['cormus', 'incendiary', 'valid']
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="question-11"&gt;
&lt;h3&gt;2.3 Question 11&lt;/h3&gt;
&lt;p&gt;For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance"&gt;Edit (Levenshtein) distance&lt;/a&gt; on the two words with transpositions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This function should return a list of length three:&lt;/strong&gt; &lt;tt class="docutils literal"&gt;['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']&lt;/tt&gt;.&lt;/p&gt;
&lt;pre class="code ipython"&gt;&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;answer_eleven&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cormulent'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'incendenece'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'validrate'&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-2"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;"""gets the nearest words based on Levenshtein distance&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-4"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-5"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     entries (list[str]): words to find closest words to&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-7"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-8"&gt;&lt;/a&gt;&lt;span class="sd"&gt;     list[str]: nearest words to the entries&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-9"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;outcomes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-12"&gt;&lt;/a&gt;        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;edit_distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-13"&gt;&lt;/a&gt;                                    &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-14"&gt;&lt;/a&gt;                     &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;correct_spellings&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-15"&gt;&lt;/a&gt;        &lt;span class="n"&gt;closest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-16"&gt;&lt;/a&gt;        &lt;span class="n"&gt;outcomes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;closest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;outcomes&lt;/span&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_838c87d989434e3eb38cdb6bab7f7392-19"&gt;&lt;/a&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;answer_eleven&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="literal-block"&gt;
['corpulent', 'intendence', 'validate']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>text nltk nlp</category><guid>https://necromuralist.github.io/data_science/posts/assignment-2-introduction-to-nltk/</guid><pubDate>Sat, 12 Aug 2017 22:02:00 GMT</pubDate></item></channel></rss>